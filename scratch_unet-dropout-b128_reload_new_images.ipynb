{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image \n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "\n",
    "from modules.scandata import MriScan, MriSlice, TumourSegmentation, ScanType, ScanPlane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "#import tensorflow_datasets as tfds\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from IPython.display import clear_output\n",
    "RSEED=123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_logical_devices('TPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='local')\n",
    "tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
    "tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
    "strategy = tf.distribute.TPUStrategy(cluster_resolver)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "buffer_size = 1000\n",
    "img_height = 240\n",
    "img_width = 240\n",
    "scan_channels = 4\n",
    "output_classes = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colour_list = ['w', '#d73027', '#91bfdb', '0.8', '#fee090']\n",
    "cmap = ListedColormap(colour_list)\n",
    "\n",
    "def display(display_list):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.utils.array_to_img(display_list[i]),cmap=cmap)\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "  \n",
    "def create_mask(pred_mask):\n",
    "    pred_mask = tf.math.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    return pred_mask[0]\n",
    "\n",
    "def show_predictions(dataset=None, num=1):\n",
    "    if dataset:\n",
    "        for image, mask in dataset.take(num):\n",
    "            pred_mask = model.predict(image)\n",
    "        display([image[0], mask[0], create_mask(pred_mask)])\n",
    "    else:\n",
    "        display([sample_image, sample_mask,\n",
    "            create_mask(model.predict(sample_image[tf.newaxis, ...]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_dir = os.path.join('data','UPENN-GBM','slice_segmentation_stratify_healthy_dropbg','train','image_data')\n",
    "train_map_dir = os.path.join('data','UPENN-GBM','slice_segmentation_stratify_healthy_dropbg','train','map_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filenames = os.listdir(train_image_dir)\n",
    "map_filenames = [filename.replace('allseq', 'map') for filename in image_filenames]\n",
    "image_filepaths = [os.path.join(train_image_dir,filename) for filename in image_filenames]\n",
    "map_filepaths = [os.path.join(train_map_dir,filename) for filename in map_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaler_0_1(x):\n",
    "    return x/255.0\n",
    "\n",
    "def scaler_neg1_1(x):\n",
    "    return x/127.5 - 1\n",
    "\n",
    "def alter_segmap(x):\n",
    "    return tf.where(x==4,tf.constant(3,dtype='uint8'),x)\n",
    "\n",
    "def read_image_map(image, seg_map):\n",
    "   image = tf.io.read_file(image)\n",
    "   image = tf.io.decode_png(image, channels=4)\n",
    "   seg_map = tf.io.read_file(seg_map)\n",
    "   seg_map = tf.io.decode_png(seg_map, channels=1)\n",
    "   # Change scaler below to scaler_0_1 to get initial values between 0 and 1\n",
    "   return scaler_neg1_1(tf.cast(image, 'float32')) ,seg_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define convolution layer steps\n",
    "initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "def horizontal_convolution(input, num_filters, dropout_rate=0.0):\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        filters=num_filters,\n",
    "        kernel_size=3,\n",
    "        padding= 'same',\n",
    "        strides=1,\n",
    "        kernel_initializer=initializer,\n",
    "        use_bias=False,\n",
    "    )(input)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(rate=dropout_rate)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x) \n",
    "    return x\n",
    "\n",
    "\n",
    "def down_step(input, num_filters, dropout_rate=0.0):\n",
    "    x = horizontal_convolution(\n",
    "        input=input,\n",
    "        num_filters=num_filters,\n",
    "        dropout_rate=dropout_rate,\n",
    "    )\n",
    "    horizontal_out = horizontal_convolution(\n",
    "        x, \n",
    "        num_filters=num_filters,\n",
    "        dropout_rate=dropout_rate,\n",
    "    )\n",
    "    down_out = tf.keras.layers.MaxPooling2D(\n",
    "        pool_size=2,\n",
    "        strides=2, \n",
    "        padding = 'same'\n",
    "    )(horizontal_out)\n",
    "    return down_out, horizontal_out\n",
    "\n",
    "\n",
    "def up_step(\n",
    "    up_input, \n",
    "    horizontal_input, \n",
    "    num_filters, \n",
    "    dropout_rate=0.0, \n",
    "):\n",
    "    x = tf.keras.layers.Conv2DTranspose(\n",
    "        filters=num_filters,\n",
    "        kernel_size=3, \n",
    "        strides=2,\n",
    "        padding='same',\n",
    "        kernel_initializer=initializer,\n",
    "        use_bias=False,\n",
    "    )(up_input)\n",
    "    x = tf.keras.layers.Concatenate()([x, horizontal_input])\n",
    "    x = horizontal_convolution(\n",
    "        x, \n",
    "        num_filters=num_filters, \n",
    "        dropout_rate=dropout_rate\n",
    "    )\n",
    "    x = horizontal_convolution(\n",
    "        x, \n",
    "        num_filters=num_filters, \n",
    "        dropout_rate=dropout_rate\n",
    "    )\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define U-Net topology\n",
    "def unet(\n",
    "    input_shape, \n",
    "    output_channels, \n",
    "    scale_filters=1.0, \n",
    "    dropout_rate=0.0,\n",
    "    final_dropout=True\n",
    "    ):\n",
    "\n",
    "    final_dropout_rate=0.0\n",
    "    if final_dropout:\n",
    "        final_dropout_rate = dropout_rate\n",
    "\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "\n",
    "    down_1, cross_1 = down_step(\n",
    "        inputs, \n",
    "        int(64*scale_filters), \n",
    "        dropout_rate=dropout_rate\n",
    "    )  # 240 -> 120\n",
    "    down_2, cross_2 = down_step(\n",
    "        down_1, \n",
    "        int(128*scale_filters), \n",
    "        dropout_rate=dropout_rate\n",
    "    )  # 120 -> 60\n",
    "    down_3, cross_3 = down_step(\n",
    "        down_2, \n",
    "        int(256*scale_filters), \n",
    "        dropout_rate=dropout_rate\n",
    "    )  # 60 -> 30\n",
    "    down_4, cross_4 = down_step(\n",
    "        down_3, \n",
    "        int(512*scale_filters), \n",
    "        dropout_rate=dropout_rate\n",
    "    )  # 30 -> 15\n",
    "\n",
    "    bottom = horizontal_convolution(\n",
    "        down_4, \n",
    "        int(1024*scale_filters), \n",
    "        dropout_rate=dropout_rate\n",
    "    )\n",
    "\n",
    "    up_4 = up_step(\n",
    "        bottom, \n",
    "        cross_4, \n",
    "        int(512*scale_filters), \n",
    "        dropout_rate=dropout_rate\n",
    "    )  # 15 -> 30\n",
    "    up_3 = up_step(\n",
    "        up_4, \n",
    "        cross_3, \n",
    "        int(256*scale_filters), \n",
    "        dropout_rate=dropout_rate\n",
    "    )  # 30 -> 60\n",
    "    up_2 = up_step(\n",
    "        up_3, \n",
    "        cross_2, \n",
    "        int(128*scale_filters), \n",
    "        dropout_rate=dropout_rate\n",
    "    )  # 60 -> 120\n",
    "    up_1 = up_step(\n",
    "        up_2, \n",
    "        cross_1, \n",
    "        int(64*scale_filters), \n",
    "        dropout_rate=final_dropout_rate\n",
    "    )  # 120 -> 240\n",
    "    \n",
    "    outputs = horizontal_convolution(up_1, output_channels)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    input_shape = (img_width,img_height,scan_channels)\n",
    "    model = unet(\n",
    "        input_shape=input_shape, \n",
    "        output_channels=output_classes, \n",
    "        dropout_rate=0.2\n",
    "    )\n",
    "    model.load_weights(\n",
    "        'model_checkpoints/unet_bs128_pat10_dr0.2_lr0.0001_scratch-2022-12-03-22:56:03-085-0.0323.ckpt'\n",
    "        )\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001,),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test data\n",
    "test_image_dir = os.path.join('data','UPENN-GBM','slice_segmentation_stratify_healthy','test','image_data')\n",
    "test_map_dir = os.path.join('data','UPENN-GBM','slice_segmentation_stratify_healthy','test','map_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_image_filenames = os.listdir(test_image_dir)\n",
    "test_image_filepaths = [os.path.join(test_image_dir,x) for x in test_image_filenames]\n",
    "test_map_filepaths = [\n",
    "    os.path.join(test_map_dir,x.replace('allseq','map')) for x in test_image_filenames\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_data = tf.data.Dataset.list_files(test_image_filepaths, shuffle=False)\n",
    "test_map_data = tf.data.Dataset.list_files(test_map_filepaths, shuffle=False)\n",
    "test_data = tf.data.Dataset.zip((test_image_data, test_map_data))\n",
    "test_batch = (\n",
    "    test_data\n",
    "    .shuffle(buffer_size, seed=tf.constant(RSEED,dtype='int64'))\n",
    "    .map(read_image_map)\n",
    "    .batch(32),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, masks = next(iter(test_batch[0].take(1)))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num=30\n",
    "sample_image, sample_mask = images[num], masks[num]\n",
    "show_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_patients = list(set([filename[:15] for filename in test_image_filenames]))\n",
    "\n",
    "\n",
    "for patient in test_patients:\n",
    "    for pred_slice in range(155):\n",
    "        scan_image_name = f'{patient}_11_allseq_{pred_slice:03}.png'\n",
    "        scan_image = tf.io.read_file(os.path.join(test_image_dir,scan_image_name))\n",
    "        scan_image = tf.io.decode_png(scan_image, channels=4)\n",
    "        scan_map = np.array(Image.open(\n",
    "            os.path.join(test_map_dir,scan_image_name.replace('allseq','map'))\n",
    "        ))\n",
    "        tensor_image = tf.expand_dims(\n",
    "            scaler_neg1_1(tf.cast(scan_image, 'float32')),\n",
    "            0\n",
    "        )\n",
    "        \n",
    "        pred_map = np.squeeze(np.argmax(model.predict(tensor_image), axis=-1))\n",
    "        pred_map[-1,-4:] = 1,2,3,4\n",
    "        scan_map[-1,-4:] = 1,2,3,4\n",
    "        plots=[pred_map]\n",
    "        cmaps=[cmap]\n",
    "        fig, axes = plt.subplots(1,1,figsize=(10, 10))\n",
    "        plt.subplots_adjust(wspace=0, hspace=0)\n",
    "        for i in range(1):\n",
    "            axes[i].imshow(plots[i], cmap=cmaps[i])\n",
    "            axes[i].axis('off')\n",
    "        plt_name = os.path.join('prediction_only',scan_image_name.replace('allseq','predmap'))\n",
    "        fig.savefig(plt_name, format='png', bbox_inches='tight')\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
