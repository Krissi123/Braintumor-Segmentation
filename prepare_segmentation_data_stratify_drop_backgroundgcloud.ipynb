{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "\n",
    "from modules.scandata import MriScan, MriSlice, TumourSegmentation, ScanType, ScanPlane, PatientRecord\n",
    "#from modules.exceptions import ScanDataDirectoryNotFound, ScanFileNotFound\n",
    "\n",
    "# Seed for test/train split and dropping images for undersampling background cases\n",
    "RSEED=78 \n",
    "\n",
    "TESTSIZE=150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScanDataDirectoryNotFound(Exception):\n",
    "    pass\n",
    "class ScanFileNotFound(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data frame of patients data files\n",
    "raw_data_dir = os.path.join('data', 'UPENN-GBM')\n",
    "raw_scan_data_dir = os.path.join(raw_data_dir, 'images_structural')\n",
    "raw_segmentation_dir = os.path.join(raw_data_dir, 'automated_segm')\n",
    "\n",
    "for dir in raw_scan_data_dir, raw_segmentation_dir:\n",
    "    if not os.path.exists(dir):\n",
    "        raise ScanDataDirectoryNotFound(f'{dir} does not exist')\n",
    "\n",
    "raw_files_list = []\n",
    "\n",
    "# Only work on preop patient data -- identifiers end *_11\n",
    "# Test set, take only TESTSIZE patients\n",
    "patients = 0\n",
    "for patient_scan_dir in glob.glob(os.path.join(raw_scan_data_dir, 'UPENN*11')):\n",
    "    patient_identifier = os.path.basename(patient_scan_dir)\n",
    "    t1_filename = os.path.join(patient_scan_dir, f'{patient_identifier}_T1.nii.gz')\n",
    "    t1ce_filename = os.path.join(patient_scan_dir, f'{patient_identifier}_T1GD.nii.gz')\n",
    "    t2_filename = os.path.join(patient_scan_dir, f'{patient_identifier}_T2.nii.gz')\n",
    "    FLAIR_filename = os.path.join(patient_scan_dir, f'{patient_identifier}_FLAIR.nii.gz')\n",
    "    seg_filename = os.path.join(\n",
    "        raw_segmentation_dir, f'{patient_identifier}_automated_approx_segm.nii.gz'\n",
    "    )\n",
    "\n",
    "    patient_raw_files = [ \n",
    "            patient_identifier, \n",
    "            patient_scan_dir,\n",
    "            t1_filename,\n",
    "            t1ce_filename,\n",
    "            t2_filename,\n",
    "            FLAIR_filename,\n",
    "            seg_filename,\n",
    "    ]\n",
    "    \n",
    "    for file in patient_raw_files[-5:]:\n",
    "        if not os.path.exists(file):\n",
    "            raise ScanFileNotFound(\n",
    "                f'{file} does not exist'\n",
    "            )\n",
    "    raw_files_list.append(patient_raw_files)\n",
    "\n",
    "    #Check if enough in testing set\n",
    "    patients += 1\n",
    "    if patients == TESTSIZE:\n",
    "        break\n",
    "\n",
    "df_patient_files = pd.DataFrame(raw_files_list, columns=[ \n",
    "            'patient_identifier', \n",
    "            'patient_scan_dir',\n",
    "            't1_filename',\n",
    "            't1ce_filename',\n",
    "            't2_filename',\n",
    "            'FLAIR_filename',\n",
    "            'seg_filename',\n",
    "])   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clinical = pd.read_csv(\n",
    "    os.path.join(raw_data_dir,'table_data','UPENN-GBM_clinical_info_v1.0.csv')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clinical['age_bin'] = '<40'\n",
    "df_clinical.loc[df_clinical['Age_at_scan_years']>=40, 'age_bin'] = '40-50'\n",
    "df_clinical.loc[df_clinical['Age_at_scan_years']>=50, 'age_bin'] = '50-60'\n",
    "df_clinical.loc[df_clinical['Age_at_scan_years']>=60, 'age_bin'] = '60-70'\n",
    "df_clinical.loc[df_clinical['Age_at_scan_years']>=70, 'age_bin'] = '70-80'\n",
    "df_clinical.loc[df_clinical['Age_at_scan_years']>=80, 'age_bin'] = '>80'\n",
    "\n",
    "df_clinical['stratify_class'] = df_clinical['Gender'] + df_clinical['age_bin']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'stratify_class' in df_patient_files.columns:\n",
    "    df_patient_files.drop('stratify_class', axis=1)\n",
    "df_patient_files = pd.merge(\n",
    "    df_patient_files, \n",
    "    df_clinical[['ID','stratify_class']], \n",
    "    how='left', \n",
    "    left_on='patient_identifier', \n",
    "    right_on='ID'\n",
    ").drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate patient data to train or test set\n",
    "patients = df_patient_files[['patient_identifier', 'stratify_class']]\n",
    "train_patients, test_patients = train_test_split(\n",
    "    patients, \n",
    "    test_size=0.5, \n",
    "    random_state=RSEED,\n",
    "    stratify=df_patient_files.stratify_class\n",
    ")\n",
    "df_train_patients = pd.DataFrame(train_patients)\n",
    "df_test_patients = pd.DataFrame(test_patients)\n",
    "df_train_patients['test_train_set'] = 'train'\n",
    "df_test_patients['test_train_set'] = 'test'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    " #df_slices = df_slices.merge(\n",
    "df_patient_files = pd.merge(\n",
    "    df_patient_files,\n",
    "    pd.concat([df_test_patients, df_train_patients]).drop('stratify_class', axis=1),\n",
    "    on='patient_identifier',\n",
    "    how='left',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create segmentation directories\n",
    "segmentation_data_dir = os.path.join(raw_data_dir, f'slice_segmentation_stratify_sample{TESTSIZE}')\n",
    "images_dir_name = 'image_data'\n",
    "map_dir_name = 'map_data'\n",
    "try:\n",
    "    os.mkdir(segmentation_data_dir)\n",
    "except:\n",
    "    print(f'{segmentation_data_dir} already exists')\n",
    "\n",
    "# Split into test and train\n",
    "for data_set in 'test', 'train':\n",
    "    data_set_dir = os.path.join(segmentation_data_dir, data_set)\n",
    "    try:\n",
    "        os.mkdir(data_set_dir)\n",
    "    except:\n",
    "        print(f'{data_set_dir} already exists')\n",
    "\n",
    "    for image_class in [images_dir_name, map_dir_name]:\n",
    "        class_dir = os.path.join(data_set_dir, image_class)\n",
    "        try:\n",
    "            os.mkdir(class_dir)\n",
    "        except:\n",
    "            print(f'{class_dir} already exists')\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/UPENN-GBM/slice_segmentation_stratify_sample150/train/image_data/data/UPENN-GBM/slice_segmentation_stratify_sample150/train/image_data/UPENN-GBM-00563_11_allseq_000.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 42\u001b[0m\n\u001b[1;32m     30\u001b[0m png_image_prefix \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\n\u001b[1;32m     31\u001b[0m     segmentation_data_dir,\n\u001b[1;32m     32\u001b[0m     test_train_set,\n\u001b[1;32m     33\u001b[0m     images_dir_name,\n\u001b[1;32m     34\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mrow\u001b[39m.\u001b[39mpatient_identifier\u001b[39m}\u001b[39;00m\u001b[39m_allseq\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     35\u001b[0m )\n\u001b[1;32m     36\u001b[0m png_map_prefix \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\n\u001b[1;32m     37\u001b[0m     segmentation_data_dir,\n\u001b[1;32m     38\u001b[0m     test_train_set,\n\u001b[1;32m     39\u001b[0m     map_dir_name,\n\u001b[1;32m     40\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mrow\u001b[39m.\u001b[39mpatient_identifier\u001b[39m}\u001b[39;00m\u001b[39m_map\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     41\u001b[0m )\n\u001b[0;32m---> 42\u001b[0m patient_data\u001b[39m.\u001b[39;49msave_multi_channel_png(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(\n\u001b[1;32m     43\u001b[0m     segmentation_data_dir,\n\u001b[1;32m     44\u001b[0m     test_train_set,\n\u001b[1;32m     45\u001b[0m     images_dir_name,\n\u001b[1;32m     46\u001b[0m     png_image_prefix,\n\u001b[1;32m     47\u001b[0m ))\n\u001b[1;32m     48\u001b[0m patient_data\u001b[39m.\u001b[39msave_segmentation_png(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\n\u001b[1;32m     49\u001b[0m     segmentation_data_dir,\n\u001b[1;32m     50\u001b[0m     test_train_set,\n\u001b[1;32m     51\u001b[0m     map_dir_name,\n\u001b[1;32m     52\u001b[0m     png_map_prefix,\n\u001b[1;32m     53\u001b[0m ))\n\u001b[1;32m     55\u001b[0m \u001b[39m# Loop through created scan pngs and remove 95% of images with no brain\u001b[39;00m\n",
      "File \u001b[0;32m~/Braintumor-Segmentation/modules/scandata.py:465\u001b[0m, in \u001b[0;36mPatientRecord.save_multi_channel_png\u001b[0;34m(self, file_prefix, sequence_list, plane, start_index)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[39mfor\u001b[39;00m idx, slice_array \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_data):\n\u001b[1;32m    461\u001b[0m     bitmap \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(\n\u001b[1;32m    462\u001b[0m         (slice_array \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscaling_factor)\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39muint8\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m    463\u001b[0m         mode \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mRGBA\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    464\u001b[0m     )\n\u001b[0;32m--> 465\u001b[0m     bitmap\u001b[39m.\u001b[39;49msave(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00mfile_prefix\u001b[39m}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mstart_index\u001b[39m+\u001b[39;49midx\u001b[39m:\u001b[39;49;00m\u001b[39m0\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mint\u001b[39;49m(width)\u001b[39m}\u001b[39;49;00m\u001b[39m}\u001b[39;49;00m\u001b[39m.png\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/PIL/Image.py:2317\u001b[0m, in \u001b[0;36mImage.save\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2315\u001b[0m         fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39mopen(filename, \u001b[39m\"\u001b[39m\u001b[39mr+b\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   2316\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2317\u001b[0m         fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39;49mopen(filename, \u001b[39m\"\u001b[39;49m\u001b[39mw+b\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   2319\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   2320\u001b[0m     save_handler(\u001b[39mself\u001b[39m, fp, filename)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/UPENN-GBM/slice_segmentation_stratify_sample150/train/image_data/data/UPENN-GBM/slice_segmentation_stratify_sample150/train/image_data/UPENN-GBM-00563_11_allseq_000.png'"
     ]
    }
   ],
   "source": [
    "deleted_slices = 0\n",
    "for idx, row in enumerate(df_patient_files.itertuples()):\n",
    "    test_train_set = row.test_train_set\n",
    "    T1_scan = MriScan(\n",
    "        filename=row.t1_filename,\n",
    "        sequence=ScanType.T1\n",
    "    )\n",
    "    T1CE_scan = MriScan(\n",
    "        filename=row.t1ce_filename,\n",
    "        sequence=ScanType.T1CE\n",
    "    )\n",
    "    T2_scan = MriScan(\n",
    "        filename=row.t2_filename,\n",
    "        sequence=ScanType.T2\n",
    "    )\n",
    "    FLAIR_scan = MriScan(\n",
    "        filename=row.FLAIR_filename,\n",
    "        sequence=ScanType.FLAIR\n",
    "    )\n",
    "    segmentation = TumourSegmentation(\n",
    "        row.seg_filename,\n",
    "        scale_png_data=False\n",
    "        )\n",
    "    patient_data = PatientRecord()\n",
    "    patient_data.add_scan_data(T1_scan)\n",
    "    patient_data.add_scan_data(T1CE_scan)\n",
    "    patient_data.add_scan_data(T2_scan)\n",
    "    patient_data.add_scan_data(FLAIR_scan)\n",
    "    patient_data.add_segmentation(segmentation)\n",
    "    png_image_prefix = os.path.join(\n",
    "        segmentation_data_dir,\n",
    "        test_train_set,\n",
    "        images_dir_name,\n",
    "        f'{row.patient_identifier}_allseq',\n",
    "    )\n",
    "    png_map_prefix = os.path.join(\n",
    "        segmentation_data_dir,\n",
    "        test_train_set,\n",
    "        map_dir_name,\n",
    "        f'{row.patient_identifier}_map',\n",
    "    )\n",
    "    patient_data.save_multi_channel_png(png_image_prefix)\n",
    "    patient_data.save_segmentation_png(png_map_prefix)\n",
    "\n",
    "    # Loop through created scan pngs and remove 95% of images with no brain\n",
    "    slice_count = len(glob.glob(f'{png_image_prefix}*'))\n",
    "    for i in range(slice_count):\n",
    "        img_file = f'{png_image_prefix}_{i:03}.png'\n",
    "        img = np.array(Image.open(img_file))\n",
    "        if img.max() == 0 and np.random.rand() > 0.05:\n",
    "            os.remove(img_file)\n",
    "            os.remove(f'{png_map_prefix}_{i:03}.png')\n",
    "            deleted_slices += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
