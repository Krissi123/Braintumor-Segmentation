{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "\n",
    "from modules.scandata import MriScan, MriSlice, TumourSegmentation, ScanType, ScanPlane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 10:16:53.836976: I tensorflow/core/tpu/tpu_api_dlsym_initializer.cc:116] Libtpu path is: libtpu.so\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "#import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 10:16:58.255788: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[LogicalDevice(name='/device:TPU:0', device_type='TPU'),\n",
       " LogicalDevice(name='/device:TPU:1', device_type='TPU'),\n",
       " LogicalDevice(name='/device:TPU:2', device_type='TPU'),\n",
       " LogicalDevice(name='/device:TPU:3', device_type='TPU'),\n",
       " LogicalDevice(name='/device:TPU:4', device_type='TPU'),\n",
       " LogicalDevice(name='/device:TPU:5', device_type='TPU'),\n",
       " LogicalDevice(name='/device:TPU:6', device_type='TPU'),\n",
       " LogicalDevice(name='/device:TPU:7', device_type='TPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 10:17:04.409291: I tensorflow/compiler/xla/service/service.cc:171] XLA service 0x7030840 initialized for platform TPU (this does not guarantee that XLA will be used). Devices:\n",
      "2022-11-22 10:17:04.409350: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (0): TPU, 2a886c8\n",
      "2022-11-22 10:17:04.409356: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (1): TPU, 2a886c8\n",
      "2022-11-22 10:17:04.409361: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (2): TPU, 2a886c8\n",
      "2022-11-22 10:17:04.409366: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (3): TPU, 2a886c8\n",
      "2022-11-22 10:17:04.409371: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (4): TPU, 2a886c8\n",
      "2022-11-22 10:17:04.409376: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (5): TPU, 2a886c8\n",
      "2022-11-22 10:17:04.409381: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (6): TPU, 2a886c8\n",
      "2022-11-22 10:17:04.409386: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (7): TPU, 2a886c8\n"
     ]
    }
   ],
   "source": [
    "tf.config.list_logical_devices('TPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n",
      "INFO:tensorflow:Initializing the TPU system: local\n",
      "INFO:tensorflow:Finished initializing TPU system.\n",
      "INFO:tensorflow:Found TPU system:\n",
      "INFO:tensorflow:*** Num TPU Cores: 8\n",
      "INFO:tensorflow:*** Num TPU Workers: 1\n",
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='local')\n",
    "tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
    "tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
    "strategy = tf.distribute.TPUStrategy(cluster_resolver)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "img_height = 240\n",
    "img_width = 240\n",
    "data_dir = os.path.join('data','UPENN-GBM','slice_classification','train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 49725 files belonging to 8 classes.\n",
      "Using 39780 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    color_mode=\"rgba\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.BatchDataset"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "map() missing 1 required positional argument: 'map_func'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_ds\u001b[39m.\u001b[39;49mmap()\n",
      "\u001b[0;31mTypeError\u001b[0m: map() missing 1 required positional argument: 'map_func'"
     ]
    }
   ],
   "source": [
    "train_ds.map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 49725 files belonging to 8 classes.\n",
      "Using 9945 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    color_mode=\"rgba\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['background', 'background_contrast', 'background_edema', 'background_edema_contrast', 'background_tumour', 'background_tumour_contrast', 'background_tumour_edema', 'background_tumour_edema_contrast']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class weights to account for class imbalance\n",
    "class_weight = {\n",
    "    0: 0.35709557053442464, \n",
    "    1: 139.94103773584905, \n",
    "    2: 0.539409090909091, \n",
    "    3: 4.525244051250763, \n",
    "    4: 3708.4375, \n",
    "    5: 412.0486111111111, \n",
    "    6: 21.943417159763314, \n",
    "    7: 0.3258016692290797\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = layers.Rescaling(1./(2**8-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with strategy.scope():\n",
    "    model = Sequential([\n",
    "      layers.Rescaling(1./(2**8-1), input_shape=(img_height, img_width, 4)),\n",
    "      layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "      layers.MaxPooling2D(),\n",
    "      layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "      layers.MaxPooling2D(),\n",
    "      layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "      layers.MaxPooling2D(),\n",
    "      layers.Flatten(),\n",
    "      layers.Dense(128, activation='relu'),\n",
    "      layers.Dense(num_classes)\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=20\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs,\n",
    "  class_weight=class_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    layers.RandomFlip(\"horizontal\",\n",
    "                      input_shape=(img_height,\n",
    "                                  img_width,\n",
    "                                  4)),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "  ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, _ in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    #with tf.device('/CPU:0'):\n",
    "    augmented_images = data_augmentation(images)\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 10:19:58.567593: W tensorflow/compiler/tf2xla/kernels/random_ops.cc:57] Warning: Using tf.random.uniform with XLA compilation will ignore seeds; consider using tf.random.stateless_uniform instead if reproducible behavior is desired. RandomUniform\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    model = Sequential([\n",
    "      #data_augmentation,\n",
    "      layers.Rescaling(1./(2**8-1), input_shape=(img_height,\n",
    "                                  img_width,\n",
    "                                  4)),\n",
    "      layers.Conv2D(8, 3, padding='same', activation='relu'),\n",
    "      layers.MaxPooling2D(),\n",
    "      layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "      layers.MaxPooling2D(),\n",
    "      layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "      layers.MaxPooling2D(),\n",
    "      layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "      layers.MaxPooling2D(),\n",
    "      layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
    "      layers.MaxPooling2D(),\n",
    "      layers.Flatten(),\n",
    "      layers.Dropout(0.2),\n",
    "      layers.Dense(128, activation='relu'),\n",
    "      layers.Dropout(0.2),\n",
    "      layers.Dense(128, activation='relu'),\n",
    "      layers.Dropout(0.2),\n",
    "      layers.Dense(num_classes, name=\"outputs\")\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_2 (Rescaling)     (None, 240, 240, 4)       0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 240, 240, 8)       296       \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 120, 120, 8)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 120, 120, 16)      1168      \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 60, 60, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 60, 60, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 30, 30, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 30, 30, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 15, 15, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 15, 15, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 7, 7, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               802944    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " outputs (Dense)             (None, 8)                 1032      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 918,944\n",
      "Trainable params: 918,944\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 10:20:10.220530: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_1\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_STRING\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 39780\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\024TensorSliceDataset:0\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_STRING\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_STRING\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 10:20:13.711926: I tensorflow/core/tpu/graph_rewrite/encapsulate_tpu_computations_pass.cc:263] Subgraph fingerprint:7726921516384453180\n",
      "2022-11-22 10:20:13.822042: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:828] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/Adam/AssignAddVariableOp.\n",
      "2022-11-22 10:20:14.026399: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:828] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/Adam/AssignAddVariableOp.\n",
      "2022-11-22 10:20:18.071889: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:435] TPU host compilation cache miss: cache_key(4559137277479312852), session_name()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3/622 [..............................] - ETA: 39s - loss: 1.7150 - accuracy: 0.1094   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 10:20:22.219394: I tensorflow/core/tpu/kernels/tpu_compile_op_common.cc:180] Compilation of 4559137277479312852 with session name  took 4.147408049s and succeeded\n",
      "2022-11-22 10:20:22.229070: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:468] TPU host compilation cache: compilation complete for cache_key(4559137277479312852), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_train_function_7726921516384453180\", property.function_library_fingerprint = 13149553722443770526, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, topology.MissingChipCount() = 0, std::string(property.shapes_prefix) = \"8,240,240,4,;8,;8,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\n",
      "2022-11-22 10:20:22.229126: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:534] After adding entry for key 4559137277479312852 with session_name  cache is 1 entries (12705593 bytes),  marked for eviction 0 entries (0 bytes).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 75/622 [==>...........................] - ETA: 23s - loss: 1.9115 - accuracy: 0.3248"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 10:20:25.501826: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:435] TPU host compilation cache miss: cache_key(18267676371434993844), session_name()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 77/622 [==>...........................] - ETA: 52s - loss: 1.9651 - accuracy: 0.3255"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 10:20:29.422512: I tensorflow/core/tpu/kernels/tpu_compile_op_common.cc:180] Compilation of 18267676371434993844 with session name  took 3.920607071s and succeeded\n",
      "2022-11-22 10:20:29.429484: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:468] TPU host compilation cache: compilation complete for cache_key(18267676371434993844), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_train_function_7726921516384453180\", property.function_library_fingerprint = 13149553722443770526, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, topology.MissingChipCount() = 0, std::string(property.shapes_prefix) = \"5,240,240,4,;5,;5,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\n",
      "2022-11-22 10:20:29.429529: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:534] After adding entry for key 18267676371434993844 with session_name  cache is 2 entries (25063491 bytes),  marked for eviction 0 entries (0 bytes).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "621/622 [============================>.] - ETA: 0s - loss: 1.8413 - accuracy: 0.3113"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 10:20:52.356741: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_1\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_STRING\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 9945\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\024TensorSliceDataset:7\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_STRING\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_STRING\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "2022-11-22 10:20:53.506146: I tensorflow/core/tpu/graph_rewrite/encapsulate_tpu_computations_pass.cc:263] Subgraph fingerprint:9790963054067299412\n",
      "2022-11-22 10:20:53.541703: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:828] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n",
      "2022-11-22 10:20:53.657162: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:828] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n",
      "2022-11-22 10:20:54.085839: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:435] TPU host compilation cache miss: cache_key(2542168833923027173), session_name()\n",
      "2022-11-22 10:20:56.549413: I tensorflow/core/tpu/kernels/tpu_compile_op_common.cc:180] Compilation of 2542168833923027173 with session name  took 2.463464381s and succeeded\n",
      "2022-11-22 10:20:56.552462: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:468] TPU host compilation cache: compilation complete for cache_key(2542168833923027173), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_test_function_9790963054067299412\", property.function_library_fingerprint = 12869646956898360300, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, topology.MissingChipCount() = 0, std::string(property.shapes_prefix) = \"8,240,240,4,;8,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\n",
      "2022-11-22 10:20:56.552509: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:534] After adding entry for key 2542168833923027173 with session_name  cache is 3 entries (29781658 bytes),  marked for eviction 0 entries (0 bytes).\n",
      "2022-11-22 10:21:02.041363: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:435] TPU host compilation cache miss: cache_key(12200965989362535932), session_name()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 53s 68ms/step - loss: 1.8399 - accuracy: 0.3109 - val_loss: 1.9697 - val_accuracy: 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 10:21:04.251919: I tensorflow/core/tpu/kernels/tpu_compile_op_common.cc:180] Compilation of 12200965989362535932 with session name  took 2.210454818s and succeeded\n",
      "2022-11-22 10:21:04.254745: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:468] TPU host compilation cache: compilation complete for cache_key(12200965989362535932), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_test_function_9790963054067299412\", property.function_library_fingerprint = 12869646956898360300, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, topology.MissingChipCount() = 0, std::string(property.shapes_prefix) = \"4,240,240,4,;4,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\n",
      "2022-11-22 10:21:04.254782: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:534] After adding entry for key 12200965989362535932 with session_name  cache is 4 entries (33738814 bytes),  marked for eviction 0 entries (0 bytes).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/80\n",
      "622/622 [==============================] - 31s 50ms/step - loss: 1.7480 - accuracy: 0.1308 - val_loss: 1.9296 - val_accuracy: 0.0315\n",
      "Epoch 3/80\n",
      "622/622 [==============================] - 31s 49ms/step - loss: 1.7267 - accuracy: 0.0966 - val_loss: 1.9297 - val_accuracy: 0.2452\n",
      "Epoch 4/80\n",
      "622/622 [==============================] - 30s 49ms/step - loss: 1.7178 - accuracy: 0.1281 - val_loss: 1.9909 - val_accuracy: 0.0012\n",
      "Epoch 5/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7142 - accuracy: 0.1111 - val_loss: 1.9785 - val_accuracy: 6.0332e-04\n",
      "Epoch 6/80\n",
      "622/622 [==============================] - 30s 49ms/step - loss: 1.7398 - accuracy: 0.0794 - val_loss: 1.9730 - val_accuracy: 0.0012\n",
      "Epoch 7/80\n",
      "622/622 [==============================] - 31s 49ms/step - loss: 1.7831 - accuracy: 0.0974 - val_loss: 1.9349 - val_accuracy: 0.2444\n",
      "Epoch 8/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7155 - accuracy: 0.1151 - val_loss: 1.9887 - val_accuracy: 0.0012\n",
      "Epoch 9/80\n",
      "622/622 [==============================] - 30s 49ms/step - loss: 1.7074 - accuracy: 0.0657 - val_loss: 1.9607 - val_accuracy: 0.0315\n",
      "Epoch 10/80\n",
      "622/622 [==============================] - 29s 47ms/step - loss: 1.7141 - accuracy: 0.0891 - val_loss: 1.9522 - val_accuracy: 0.0315\n",
      "Epoch 11/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7126 - accuracy: 0.1243 - val_loss: 1.9545 - val_accuracy: 0.2444\n",
      "Epoch 12/80\n",
      "622/622 [==============================] - 29s 47ms/step - loss: 1.7354 - accuracy: 0.0828 - val_loss: 1.9687 - val_accuracy: 0.0012\n",
      "Epoch 13/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7251 - accuracy: 0.0687 - val_loss: 1.9632 - val_accuracy: 0.0315\n",
      "Epoch 14/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7099 - accuracy: 0.0763 - val_loss: 1.9480 - val_accuracy: 0.2444\n",
      "Epoch 15/80\n",
      "622/622 [==============================] - 30s 49ms/step - loss: 1.7357 - accuracy: 0.1398 - val_loss: 2.0225 - val_accuracy: 0.0012\n",
      "Epoch 16/80\n",
      "622/622 [==============================] - 30s 49ms/step - loss: 1.7286 - accuracy: 0.1475 - val_loss: 1.9754 - val_accuracy: 0.0012\n",
      "Epoch 17/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7934 - accuracy: 0.1162 - val_loss: 1.8199 - val_accuracy: 0.4061\n",
      "Epoch 18/80\n",
      "622/622 [==============================] - 31s 49ms/step - loss: 1.7548 - accuracy: 0.1089 - val_loss: 2.0007 - val_accuracy: 6.0332e-04\n",
      "Epoch 19/80\n",
      "622/622 [==============================] - 31s 49ms/step - loss: 1.7036 - accuracy: 0.0202 - val_loss: 1.9527 - val_accuracy: 0.0315\n",
      "Epoch 20/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7075 - accuracy: 0.0883 - val_loss: 1.9423 - val_accuracy: 0.0315\n",
      "Epoch 21/80\n",
      "622/622 [==============================] - 29s 47ms/step - loss: 1.7033 - accuracy: 0.1550 - val_loss: 1.9320 - val_accuracy: 0.4060\n",
      "Epoch 22/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7085 - accuracy: 0.1637 - val_loss: 1.9395 - val_accuracy: 0.0315\n",
      "Epoch 23/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7091 - accuracy: 0.2047 - val_loss: 1.9424 - val_accuracy: 0.0315\n",
      "Epoch 24/80\n",
      "622/622 [==============================] - 29s 47ms/step - loss: 1.7135 - accuracy: 0.1165 - val_loss: 1.9473 - val_accuracy: 0.0315\n",
      "Epoch 25/80\n",
      "622/622 [==============================] - 29s 47ms/step - loss: 1.7463 - accuracy: 0.0892 - val_loss: 1.9583 - val_accuracy: 0.0315\n",
      "Epoch 26/80\n",
      "622/622 [==============================] - 29s 47ms/step - loss: 1.7097 - accuracy: 0.0761 - val_loss: 1.9498 - val_accuracy: 0.0315\n",
      "Epoch 27/80\n",
      "622/622 [==============================] - 29s 47ms/step - loss: 1.6993 - accuracy: 0.1220 - val_loss: 1.9408 - val_accuracy: 0.0315\n",
      "Epoch 28/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7087 - accuracy: 0.1697 - val_loss: 1.9404 - val_accuracy: 0.0315\n",
      "Epoch 29/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.6993 - accuracy: 0.1012 - val_loss: 1.9410 - val_accuracy: 0.2444\n",
      "Epoch 30/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7118 - accuracy: 0.1127 - val_loss: 1.9251 - val_accuracy: 0.2444\n",
      "Epoch 31/80\n",
      "622/622 [==============================] - 31s 49ms/step - loss: 1.7114 - accuracy: 0.0656 - val_loss: 1.9317 - val_accuracy: 0.0315\n",
      "Epoch 32/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7040 - accuracy: 0.1041 - val_loss: 1.9336 - val_accuracy: 0.2444\n",
      "Epoch 33/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7077 - accuracy: 0.2185 - val_loss: 1.9594 - val_accuracy: 0.0315\n",
      "Epoch 34/80\n",
      "622/622 [==============================] - 30s 47ms/step - loss: 1.7130 - accuracy: 0.0886 - val_loss: 1.9518 - val_accuracy: 0.0315\n",
      "Epoch 35/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7098 - accuracy: 0.0592 - val_loss: 1.9631 - val_accuracy: 0.0315\n",
      "Epoch 36/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7085 - accuracy: 0.1076 - val_loss: 1.9119 - val_accuracy: 0.0315\n",
      "Epoch 37/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7093 - accuracy: 0.0678 - val_loss: 1.9414 - val_accuracy: 0.0315\n",
      "Epoch 38/80\n",
      "622/622 [==============================] - 29s 47ms/step - loss: 1.7023 - accuracy: 0.1448 - val_loss: 1.9438 - val_accuracy: 0.0315\n",
      "Epoch 39/80\n",
      "622/622 [==============================] - 30s 49ms/step - loss: 1.7071 - accuracy: 0.0331 - val_loss: 1.9344 - val_accuracy: 0.0315\n",
      "Epoch 40/80\n",
      "622/622 [==============================] - 30s 49ms/step - loss: 1.7087 - accuracy: 0.1027 - val_loss: 1.9359 - val_accuracy: 0.2444\n",
      "Epoch 41/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7102 - accuracy: 0.0877 - val_loss: 1.9439 - val_accuracy: 0.0315\n",
      "Epoch 42/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.6967 - accuracy: 0.1408 - val_loss: 1.9279 - val_accuracy: 0.0315\n",
      "Epoch 43/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7065 - accuracy: 0.0474 - val_loss: 1.9408 - val_accuracy: 0.0315\n",
      "Epoch 44/80\n",
      "622/622 [==============================] - 30s 49ms/step - loss: 1.7057 - accuracy: 0.1077 - val_loss: 1.9385 - val_accuracy: 0.0315\n",
      "Epoch 45/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7060 - accuracy: 0.0541 - val_loss: 1.9366 - val_accuracy: 0.0315\n",
      "Epoch 46/80\n",
      "622/622 [==============================] - 30s 49ms/step - loss: 1.7090 - accuracy: 0.0361 - val_loss: 1.9568 - val_accuracy: 0.0315\n",
      "Epoch 47/80\n",
      "622/622 [==============================] - 30s 49ms/step - loss: 1.7071 - accuracy: 0.0388 - val_loss: 1.9470 - val_accuracy: 0.0315\n",
      "Epoch 48/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7095 - accuracy: 0.0822 - val_loss: 1.9456 - val_accuracy: 0.0315\n",
      "Epoch 49/80\n",
      "622/622 [==============================] - 30s 47ms/step - loss: 1.7036 - accuracy: 0.1702 - val_loss: 1.9542 - val_accuracy: 0.0315\n",
      "Epoch 50/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7042 - accuracy: 0.0327 - val_loss: 1.9499 - val_accuracy: 0.0315\n",
      "Epoch 51/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7109 - accuracy: 0.0444 - val_loss: 1.9564 - val_accuracy: 0.0315\n",
      "Epoch 52/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7079 - accuracy: 0.1014 - val_loss: 1.9553 - val_accuracy: 0.0315\n",
      "Epoch 53/80\n",
      "622/622 [==============================] - 29s 47ms/step - loss: 1.6998 - accuracy: 0.0474 - val_loss: 1.9318 - val_accuracy: 0.0315\n",
      "Epoch 54/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7131 - accuracy: 0.0975 - val_loss: 1.9602 - val_accuracy: 0.0315\n",
      "Epoch 55/80\n",
      "622/622 [==============================] - 30s 49ms/step - loss: 1.7068 - accuracy: 0.0307 - val_loss: 1.9503 - val_accuracy: 0.0315\n",
      "Epoch 56/80\n",
      "622/622 [==============================] - 29s 47ms/step - loss: 1.7081 - accuracy: 0.0288 - val_loss: 1.9437 - val_accuracy: 0.0315\n",
      "Epoch 57/80\n",
      "622/622 [==============================] - 29s 47ms/step - loss: 1.7061 - accuracy: 0.1180 - val_loss: 1.9388 - val_accuracy: 0.0315\n",
      "Epoch 58/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7040 - accuracy: 0.0625 - val_loss: 1.9258 - val_accuracy: 0.0315\n",
      "Epoch 59/80\n",
      "622/622 [==============================] - 30s 49ms/step - loss: 1.7098 - accuracy: 0.2171 - val_loss: 1.9420 - val_accuracy: 0.0315\n",
      "Epoch 60/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7088 - accuracy: 0.1328 - val_loss: 1.9367 - val_accuracy: 0.0315\n",
      "Epoch 61/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7018 - accuracy: 0.0537 - val_loss: 1.9555 - val_accuracy: 0.0315\n",
      "Epoch 62/80\n",
      "622/622 [==============================] - 30s 49ms/step - loss: 1.7070 - accuracy: 0.0797 - val_loss: 1.9503 - val_accuracy: 0.0315\n",
      "Epoch 63/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7063 - accuracy: 0.1180 - val_loss: 1.9569 - val_accuracy: 0.0315\n",
      "Epoch 64/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7072 - accuracy: 0.0371 - val_loss: 1.9544 - val_accuracy: 0.0315\n",
      "Epoch 65/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7056 - accuracy: 0.0414 - val_loss: 1.9544 - val_accuracy: 0.0315\n",
      "Epoch 66/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7058 - accuracy: 0.0232 - val_loss: 1.9507 - val_accuracy: 0.0315\n",
      "Epoch 67/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7068 - accuracy: 0.0330 - val_loss: 1.9480 - val_accuracy: 0.0315\n",
      "Epoch 68/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7099 - accuracy: 0.0381 - val_loss: 1.9606 - val_accuracy: 0.0315\n",
      "Epoch 69/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7071 - accuracy: 0.0244 - val_loss: 1.9568 - val_accuracy: 0.0315\n",
      "Epoch 70/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7059 - accuracy: 0.0300 - val_loss: 1.9584 - val_accuracy: 0.0315\n",
      "Epoch 71/80\n",
      "622/622 [==============================] - 31s 49ms/step - loss: 1.7041 - accuracy: 0.0312 - val_loss: 1.9518 - val_accuracy: 0.0315\n",
      "Epoch 72/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7060 - accuracy: 0.0395 - val_loss: 1.9610 - val_accuracy: 0.0315\n",
      "Epoch 73/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7086 - accuracy: 0.0253 - val_loss: 1.9600 - val_accuracy: 0.0315\n",
      "Epoch 74/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7036 - accuracy: 0.0533 - val_loss: 1.9543 - val_accuracy: 0.0315\n",
      "Epoch 75/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7064 - accuracy: 0.0304 - val_loss: 1.9517 - val_accuracy: 0.0315\n",
      "Epoch 76/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7086 - accuracy: 0.0516 - val_loss: 1.9605 - val_accuracy: 0.0315\n",
      "Epoch 77/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7071 - accuracy: 0.0279 - val_loss: 1.9597 - val_accuracy: 0.0315\n",
      "Epoch 78/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7055 - accuracy: 0.0482 - val_loss: 1.9507 - val_accuracy: 0.0315\n",
      "Epoch 79/80\n",
      "622/622 [==============================] - 30s 49ms/step - loss: 1.7064 - accuracy: 0.1664 - val_loss: 1.9531 - val_accuracy: 0.0315\n",
      "Epoch 80/80\n",
      "622/622 [==============================] - 30s 48ms/step - loss: 1.7049 - accuracy: 0.0335 - val_loss: 1.9515 - val_accuracy: 0.0315\n"
     ]
    }
   ],
   "source": [
    "epochs = 80\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs,\n",
    "  class_weight=class_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
