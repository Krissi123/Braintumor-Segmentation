{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "\n",
    "from modules.scandata import MriScan, MriSlice, TumourSegmentation, ScanType, ScanPlane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "#import tensorflow_datasets as tfds\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_logical_devices('TPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='local')\n",
    "tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
    "tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
    "strategy = tf.distribute.TPUStrategy(cluster_resolver)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "img_height = 240\n",
    "img_width = 240\n",
    "data_dir = os.path.join('data','UPENN-GBM','slice_classification_common_stratify','train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    color_mode=\"rgba\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    color_mode=\"rgba\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Calculate class weights ofr weighting accuracy\n",
    "ds_classes = []\n",
    "for _, batch_classes in train_ds:\n",
    "    ds_classes.append(batch_classes.numpy())\n",
    "\n",
    "ds_classes = np.concatenate(ds_classes)\n",
    "\n",
    "class_weight = compute_class_weight(\n",
    "    class_weight = 'balanced',\n",
    "    classes = np.unique(ds_classes),\n",
    "    y=ds_classes\n",
    ")\n",
    "\n",
    "class_weight = dict(zip(np.unique(ds_classes), class_weight))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = layers.Rescaling(1./(2**8-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = 8\n",
    "scaled_height = img_height - 2*margin\n",
    "scaled_width = img_width - 2*margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build layers for model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with strategy.scope():\n",
    "    crop_layer = tf.keras.layers.Cropping2D(margin)\n",
    "    #rescale_initial = tf.keras.layers.Rescaling(1./127.5, offset=-1)\n",
    "    rescale_initial = tf.keras.layers.Rescaling(1./255)\n",
    "    conv_4to3_channel = tf.keras.layers.Conv2D(3,1,padding='same', activation='tanh')\n",
    "    trained_base_model = tf.keras.applications.MobileNetV2(\n",
    "        input_shape=(scaled_width,scaled_height,3),\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "    prediction_layer = tf.keras.layers.Dense(num_classes)\n",
    "\n",
    "    trained_base_model.trainable = False\n",
    "    \n",
    "    inputs = tf.keras.Input(shape=(img_width, img_height, 4))\n",
    "    x = crop_layer(inputs)\n",
    "    x = rescale_initial(x)\n",
    "    x = conv_4to3_channel(x)\n",
    "    x = trained_base_model(x, training=False)\n",
    "    x = global_average_layer(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    outputs = prediction_layer(x)\n",
    "   \n",
    "    earlystopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "         patience=3,\n",
    "         min_delta=0.001)\n",
    "    \n",
    "    model_fixed_base = tf.keras.Model(inputs, outputs)\n",
    "    model_fixed_base.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fixed_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model_fixed_base, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_model_epochs=80\n",
    "history_model_fixed_base = model_fixed_base.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=small_model_epochs,\n",
    "  class_weight=class_weight,\n",
    "  callbacks=[earlystopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_outputs = [layer.output for layer in model_fixed_base.layers[:4]]\n",
    "vis_model = tf.keras.models.Model(\n",
    "    inputs=model_fixed_base.input, \n",
    "    outputs=layer_outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#((activations[-1][1,:,:,:]+1)*127.5).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 40))\n",
    "batch = train_ds.take(1)\n",
    "#activations = vis_model.predict(batch)\n",
    "for images, labels in batch:\n",
    "  for i in range(64):\n",
    "    image = np.expand_dims(images[i], axis=0)\n",
    "    activation = vis_model.predict(image)\n",
    "    ax = plt.subplot(16, 4, i + 1)\n",
    "    plt.imshow(((activation[-1][0,:,:,:]+1)*127.5).astype('uint8'))\n",
    "    plt.title(class_names[labels[i]], fontsize=6)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history_model_fixed_base.history['accuracy']\n",
    "val_acc = history_model_fixed_base.history['val_accuracy']\n",
    "\n",
    "loss = history_model_fixed_base.history['loss']\n",
    "val_loss = history_model_fixed_base.history['val_loss']\n",
    "\n",
    "epochs_range = range(small_model_epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_base_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_at = 100\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in trained_base_model.layers[:fine_tune_at]:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "  model_fixed_base.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy']\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuning_epochs=100\n",
    "total_epochs = small_model_epochs + fine_tuning_epochs\n",
    "history_fine_tuning = model_fixed_base.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=total_epochs,\n",
    "  initial_epoch=history_model_fixed_base.epoch[-1],\n",
    "  class_weight=class_weight,\n",
    "  callbacks=[earlystopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_outputs = [layer.output for layer in model_fixed_base.layers[:4]]\n",
    "vis_model = tf.keras.models.Model(\n",
    "    inputs=model_fixed_base.input, \n",
    "    outputs=layer_outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 40))\n",
    "for images, labels in batch:\n",
    "  for i in range(64):\n",
    "    image = np.expand_dims(images[i], axis=0)\n",
    "    activation = vis_model.predict(image)\n",
    "    ax = plt.subplot(16, 4, i + 1)\n",
    "    plt.imshow(((activation[-1][0,:,:,:]+1)*127.5).astype('uint8'))\n",
    "    plt.title(class_names[labels[i]], fontsize=6)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_fine = history_fine_tuning.history['val_accuracy']\n",
    "loss_fine = history_fine_tuning.history['val_loss']\n",
    "plt.plot(acc_fine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_base_model.trainable = True\n",
    "for layer in trained_base_model.layers:\n",
    "    print(layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "  model_fixed_base.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy']\n",
    "  )\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_relax_epochs=100\n",
    "total_epochs += full_relax_epochs\n",
    "history_fine_tuning = model_fixed_base.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=total_epochs,\n",
    "  initial_epoch=history_fine_tuning.epoch[-1],\n",
    "  class_weight=class_weight,\n",
    "  callbacks=[earlystopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_outputs = [layer.output for layer in model_fixed_base.layers[:4]]\n",
    "vis_model = tf.keras.models.Model(\n",
    "    inputs=model_fixed_base.input, \n",
    "    outputs=layer_outputs\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 40))\n",
    "#batch = train_ds.take(1)\n",
    "#activations = vis_model.predict(batch)\n",
    "for images, labels in batch:\n",
    "  for i in range(64):\n",
    "    image = np.expand_dims(images[i], axis=0)\n",
    "    activation = vis_model.predict(image)\n",
    "    ax = plt.subplot(16, 4, i + 1)\n",
    "    plt.imshow(((activation[-1][0,:,:,:]+1)*127.5).astype('uint8'))\n",
    "    plt.title(class_names[labels[i]], fontsize=6)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ch in range(3):\n",
    "\n",
    "    print(\n",
    "        (((activation[-1][:,:,:,ch]+1)*127.5).astype('uint8')).min(), \n",
    "        (((activation[-1][:,:,:,ch]+1)*127.5).astype('uint8')).max(), \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fixed_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(trained_base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    # Use the activations of these layers\n",
    "    pretrained_layer_name='mobilenetv2_1.00_224'\n",
    "    layer_names = [\n",
    "        'block_1_expand_relu',   # 64x64\n",
    "        'block_3_expand_relu',   # 32x32\n",
    "        'block_6_expand_relu',   # 16x16\n",
    "        'block_13_expand_relu',  # 8x8\n",
    "        'block_16_project',      # 4x4\n",
    "    ]\n",
    "    base_model_outputs = [\n",
    "        model_fixed_base.get_layer(pretrained_layer_name)\n",
    "        .get_layer(name).output for name in layer_names\n",
    "    ]\n",
    "\n",
    "    # Create the feature extraction model\n",
    "    down_stack = tf.keras.Model(\n",
    "        inputs=model_fixed_base.get_layer(pretrained_layer_name).input, \n",
    "        outputs=base_model_outputs\n",
    "    )\n",
    "\n",
    "    down_stack.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_stack.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for layer in model_fixed_base.get_layer(pretrained_layer_name).layers[:-4]:\n",
    "#    down_stack.get_layer(layer.name).set_weights(layer.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#down_stack.set_weights(model_fixed_base.get_layer(pretrained_layer_name).get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(down_stack, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define each layer block for upbranch\n",
    "def upsample(filters, size, norm_type='batchnorm', apply_dropout=False):\n",
    "  \"\"\"Upsamples an input.\n",
    "\n",
    "  Conv2DTranspose => Batchnorm => Dropout => Relu\n",
    "\n",
    "  Args:\n",
    "    filters: number of filters\n",
    "    size: filter size\n",
    "    norm_type: Normalization type; either 'batchnorm' or 'instancenorm'.\n",
    "    apply_dropout: If True, adds the dropout layer\n",
    "\n",
    "  Returns:\n",
    "    Upsample Sequential Model\n",
    "  \"\"\"\n",
    "\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "  result = tf.keras.Sequential()\n",
    "  result.add(\n",
    "      tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
    "                                      padding='same',\n",
    "                                      kernel_initializer=initializer,\n",
    "                                      use_bias=False))\n",
    "\n",
    "  if norm_type.lower() == 'batchnorm':\n",
    "    result.add(tf.keras.layers.BatchNormalization())\n",
    "  #elif norm_type.lower() == 'instancenorm':\n",
    "  #  result.add(InstanceNormalization())\n",
    "\n",
    "  if apply_dropout:\n",
    "    result.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "  result.add(tf.keras.layers.ReLU())\n",
    "\n",
    "  return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_stack = [\n",
    "    upsample(512, 3),  # 7x7 -> 14x14\n",
    "    upsample(256, 3),  # 14x14 -> 28x28\n",
    "    upsample(128, 3),  # 28x28 -> 56x56\n",
    "    upsample(64, 3),   # 56x56 -> 112x112\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_fixed_base.layers[1:4]:\n",
    "    print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = tf.convert_to_tensor(np.random.rand(64,240,240,4))\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.layers[2].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model(output_channels: int):\n",
    "\n",
    "    # Add layers from classification model\n",
    "    inputs = tf.keras.layers.Input(shape=[240, 240, 4])\n",
    "    x = model_fixed_base.layers[1](inputs)\n",
    "    for layer in model_fixed_base.layers[2:4]:\n",
    "        x = layer(x)\n",
    "\n",
    "    # Downsampling through the model\n",
    "    skips = down_stack(x)\n",
    "    x = skips[-1]\n",
    "    skips = reversed(skips[:-1])\n",
    "\n",
    "    # Upsampling and establishing the skip connections\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        concat = tf.keras.layers.Concatenate()\n",
    "        x = concat([x, skip])\n",
    "\n",
    "    # This is the last layer of the model\n",
    "    last_conv_trans = tf.keras.layers.Conv2DTranspose(\n",
    "        filters=output_channels, kernel_size=3, strides=2, padding=\"same\"\n",
    "    )  # 64x64 -> 128x128\n",
    "\n",
    "    x = last_conv_trans(x)\n",
    "\n",
    "    x = tf.keras.layers.ZeroPadding2D(8)(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CLASSES = 4\n",
    "with strategy.scope():\n",
    "    model = unet_model(output_channels=OUTPUT_CLASSES)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001,),\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(display_list):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.utils.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "  \n",
    "def create_mask(pred_mask):\n",
    "    pred_mask = tf.math.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    return pred_mask[0]\n",
    "\n",
    "def show_predictions(dataset=None, num=1):\n",
    "    if dataset:\n",
    "        for image, mask in dataset.take(num):\n",
    "            pred_mask = model.predict(image)\n",
    "        display([image[0], mask[0], create_mask(pred_mask)])\n",
    "    else:\n",
    "        display([sample_image, sample_mask,\n",
    "            create_mask(model.predict(sample_image[tf.newaxis, ...]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "maps = []\n",
    "\n",
    "train_image_dir = os.path.join('data','UPENN-GBM','slice_segmentation_stratify','train','image_data')\n",
    "train_map_dir = os.path.join('data','UPENN-GBM','slice_segmentation_stratify','train','map_data')\n",
    "\n",
    "pixel_counts = [0,0,0,0]\n",
    "\n",
    "for image_file in os.listdir(train_image_dir):\n",
    "    map_file = image_file.replace('allseq', 'map')\n",
    "    if not os.path.exists(os.path.join(train_map_dir,map_file)):\n",
    "        raise FileNotFoundError((image_file, map_file))\n",
    "\n",
    "    image = tf.io.read_file(os.path.join(train_image_dir,image_file))\n",
    "    image = tf.io.decode_png(image, channels=4)\n",
    "    seg_map = tf.io.read_file(os.path.join(train_map_dir,map_file))\n",
    "    seg_map = tf.io.decode_png(seg_map, channels=1)\n",
    "\n",
    "    # Convert map to make class integers contiguous\n",
    "    seg_map = seg_map.numpy()\n",
    "    seg_map[seg_map==4] = 3\n",
    "    seg_map = tf.convert_to_tensor(seg_map)\n",
    "\n",
    "    # Count pixel classes\n",
    "    indices,counts = np.unique(seg_map,return_counts=True)\n",
    "    for i, index in enumerate(indices):\n",
    "        pixel_counts[index] += counts[i]\n",
    "    \n",
    "    images.append(image)\n",
    "    maps.append(seg_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, val_images, train_maps, val_maps = train_test_split(images, maps, test_size=0.2)\n",
    "train_images = tf.convert_to_tensor(train_images)\n",
    "train_maps = tf.convert_to_tensor(train_maps)\n",
    "val_images = tf.convert_to_tensor(val_images)\n",
    "val_maps = tf.convert_to_tensor(val_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaler_0_1(x):\n",
    "    return x/255.0\n",
    "\n",
    "def scaler_neg1_1(x):\n",
    "    return x/127.5 - 1\n",
    "\n",
    "def create_dataset(img, seg_map, scaler):\n",
    "    img = scaler(tf.cast(img, tf.float32))\n",
    "    \n",
    "    return img,seg_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices(\n",
    "    create_dataset(train_images,train_maps,scaler_neg1_1)\n",
    ")\n",
    "val_data = tf.data.Dataset.from_tensor_slices(\n",
    "    create_dataset(val_images,val_maps,scaler_neg1_1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch = (\n",
    "    train_data.cache()\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .repeat()\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_batch = val_data.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, masks in train_batch.take(1):\n",
    "    sample_image, sample_mask = images[0], masks[0]\n",
    "    display([sample_image, sample_mask])\n",
    "    print(images.shape, masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        clear_output(wait=True)\n",
    "        show_predictions()\n",
    "        print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weights\n",
    "weights = 1.0/np.array(pixel_counts)\n",
    "weights = weights/np.sum(weights)\n",
    "\n",
    "def add_sample_weights(image, label):\n",
    "  # The weights for each class, with the constraint that:\n",
    "  #     sum(class_weights) == 1.0\n",
    "  #class_weights = tf.constant([2.0, 2.0, 1.0])\n",
    "  #class_weights = class_weights/tf.reduce_sum(class_weights)\n",
    "\n",
    "  # Create an image of `sample_weights` by using the label at each pixel as an \n",
    "  # index into the `class weights` .\n",
    "  sample_weights = tf.gather(weights, indices=tf.cast(label, tf.int32))\n",
    "\n",
    "  return image, label, sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr 0.00001\n",
    "TRAIN_LENGTH=68076\n",
    "EPOCHS = 40\n",
    "VAL_SUBSPLITS = 5\n",
    "VALIDATION_STEPS = 17019//BATCH_SIZE//VAL_SUBSPLITS\n",
    "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE\n",
    "\n",
    "model_history = model.fit(\n",
    "    train_batch.map(add_sample_weights), \n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    validation_steps=VALIDATION_STEPS,\n",
    "    validation_data=val_batch,\n",
    "    callbacks=[DisplayCallback()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_maps.shape\n",
    "plt.imshow(val_images[10,:,:,1],cmap='gist_gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_img = tf.expand_dims(val_images[10],0)\n",
    "single_map = tf.expand_dims(val_maps[10],0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_ds = tf.data.Dataset.from_tensor_slices(([single_img],[single_map]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for simg, smap in single_ds:\n",
    "    print(simg.shape, smap.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predictions(single_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = tf.constant([2,10,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([[0,0,0],[0,1,0],[0,1,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weights = tf.gather(weight, indices=tf.cast(arr, tf.int32))\n",
    "sample_weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
