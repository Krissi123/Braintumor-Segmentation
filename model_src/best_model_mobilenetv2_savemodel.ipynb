{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 14:58:27.403283: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-01 14:58:27.583482: I tensorflow/core/tpu/tpu_initializer_helper.cc:262] Libtpu path is: libtpu.so\n",
      "I1201 14:58:27.677741380 3012016 ev_epoll1_linux.cc:121]     grpc epoll fd: 71\n",
      "D1201 14:58:27.677764310 3012016 ev_posix.cc:141]            Using polling engine: epoll1\n",
      "D1201 14:58:27.677815385 3012016 lb_policy_registry.cc:43]   registering LB policy factory for \"grpclb\"\n",
      "D1201 14:58:27.677825793 3012016 lb_policy_registry.cc:43]   registering LB policy factory for \"rls_experimental\"\n",
      "D1201 14:58:27.677835420 3012016 lb_policy_registry.cc:43]   registering LB policy factory for \"priority_experimental\"\n",
      "D1201 14:58:27.677843225 3012016 lb_policy_registry.cc:43]   registering LB policy factory for \"weighted_target_experimental\"\n",
      "D1201 14:58:27.677846568 3012016 lb_policy_registry.cc:43]   registering LB policy factory for \"pick_first\"\n",
      "D1201 14:58:27.677849800 3012016 lb_policy_registry.cc:43]   registering LB policy factory for \"round_robin\"\n",
      "D1201 14:58:27.677858277 3012016 lb_policy_registry.cc:43]   registering LB policy factory for \"ring_hash_experimental\"\n",
      "D1201 14:58:27.677869229 3012016 dns_resolver_ares.cc:831]   Using ares dns resolver\n",
      "D1201 14:58:27.677893689 3012016 certificate_provider_registry.cc:39] registering certificate provider factory for \"file_watcher\"\n",
      "D1201 14:58:27.677901643 3012016 lb_policy_registry.cc:43]   registering LB policy factory for \"cds_experimental\"\n",
      "D1201 14:58:27.677909566 3012016 lb_policy_registry.cc:43]   registering LB policy factory for \"xds_cluster_impl_experimental\"\n",
      "D1201 14:58:27.677917630 3012016 lb_policy_registry.cc:43]   registering LB policy factory for \"xds_cluster_resolver_experimental\"\n",
      "D1201 14:58:27.677921115 3012016 lb_policy_registry.cc:43]   registering LB policy factory for \"xds_cluster_manager_experimental\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import mlflow\n",
    "from dotenv import load_dotenv\n",
    "import tensorflow as tf\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow import keras \n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "load_dotenv('../.env')\n",
    "\n",
    "RSEED = 123\n",
    "MODELS_DIR=os.path.join('..','models')\n",
    "MODEL_CHECKPOINTS_DIR=os.path.join('..','model_checkpoints')\n",
    "\n",
    "start_time = datetime.now().strftime('-%Y-%m-%d-%T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir in MODELS_DIR, MODEL_CHECKPOINTS_DIR:\n",
    "    if not os.path.exists(dir):\n",
    "        os.mkdir(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "batch_size=64\n",
    "patience=10 \n",
    "min_delta=0.001\n",
    "dropout_rate=0.25\n",
    "initial_learning_rate=0.0005\n",
    "\n",
    "\n",
    "run_name_params = (\n",
    "    f'bs{batch_size}'\n",
    "    f'_pat{patience}'\n",
    "    f'_del{min_delta}'\n",
    "    f'_dr{dropout_rate}'\n",
    "    f'_lr{initial_learning_rate}'\n",
    ")\n",
    "\n",
    "parent_run_name = f'mobilenetv2_{run_name_params}_save'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n",
      "INFO:tensorflow:Initializing the TPU system: local\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 14:58:29.957218: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-01 14:58:34.050184: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7c5d940 initialized for platform TPU (this does not guarantee that XLA will be used). Devices:\n",
      "2022-12-01 14:58:34.050224: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): TPU, 2a886c8\n",
      "2022-12-01 14:58:34.050232: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): TPU, 2a886c8\n",
      "2022-12-01 14:58:34.050238: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (2): TPU, 2a886c8\n",
      "2022-12-01 14:58:34.050244: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (3): TPU, 2a886c8\n",
      "2022-12-01 14:58:34.050250: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (4): TPU, 2a886c8\n",
      "2022-12-01 14:58:34.050255: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (5): TPU, 2a886c8\n",
      "2022-12-01 14:58:34.050261: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (6): TPU, 2a886c8\n",
      "2022-12-01 14:58:34.050267: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (7): TPU, 2a886c8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n",
      "INFO:tensorflow:Found TPU system:\n",
      "INFO:tensorflow:*** Num TPU Cores: 8\n",
      "INFO:tensorflow:*** Num TPU Workers: 1\n",
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "# Set up gcloud TPUs\n",
    "cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='local')\n",
    "tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
    "tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
    "strategy = tf.distribute.TPUStrategy(cluster_resolver)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to \n",
      " URI:https://hudsju377cddpoevnjdkfnvpwovniewnipcdsnkvn.mlflow.neuefische.de\n",
      " Expt:braintumour_mri_slice_classification\n"
     ]
    }
   ],
   "source": [
    "# Set information for mlflow\n",
    "run_description = \"\"\"\n",
    "Fully trained models \n",
    "    - classify each slice by tumour/tissue regions in the segmentation\n",
    "    - Uses MobileNetV2\n",
    "    - Saves model at end of run\n",
    "\"\"\"\n",
    "dataset = 'full_data_stratified'\n",
    "mlflow_tracking_uri = os.getenv('MLFLOW_URI')\n",
    "if mlflow_tracking_uri:\n",
    "    mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "mlflow_expt = os.getenv('CLASSIFICATION_EXPT')\n",
    "if mlflow_expt:\n",
    "    mlflow.set_experiment(mlflow_expt)    \n",
    "\n",
    "\n",
    "print(f'Logging to \\n URI:{mlflow_tracking_uri}\\n Expt:{mlflow_expt}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 49725 files belonging to 5 classes.\n",
      "Using 39780 files for training.\n",
      "Found 49725 files belonging to 5 classes.\n",
      "Using 9945 files for validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 14:58:56.497091: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2022-12-01 14:58:56.560125: I tensorflow/compiler/jit/xla_compilation_cache.cc:476] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2022-12-01 14:59:14.691897: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_1\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_STRING\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 39780\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\024TensorSliceDataset:0\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"replicate_on_split\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_STRING\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "2022/12/01 14:59:15 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during autologging: Unable to locate credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 14:59:21.273645: I tensorflow/core/tpu/graph_rewrite/encapsulate_tpu_computations_pass.cc:237] Subgraph fingerprint:10405401112127002185\n",
      "2022-12-01 14:59:21.565325: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/Adam/AssignAddVariableOp.\n",
      "2022-12-01 14:59:21.866002: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/Adam/AssignAddVariableOp.\n",
      "2022-12-01 14:59:25.896294: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:437] TPU host compilation cache miss: cache_key(6276048110352915742), session_name()\n",
      "2022-12-01 14:59:31.843313: I tensorflow/core/tpu/kernels/tpu_compile_op_common.cc:210] Compilation of 6276048110352915742 with session name  took 5.946923584s and succeeded\n",
      "2022-12-01 14:59:31.867308: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:470] TPU host compilation cache: compilation complete for cache_key(6276048110352915742), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_train_function_10405401112127002185\", property.function_library_fingerprint = 5401249623246154427, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, topology.MissingChipCount() = 0, std::string(property.shapes_prefix) = \"8,240,240,4,;8,;8,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\n",
      "2022-12-01 14:59:31.867358: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:536] After adding entry for key 6276048110352915742 with session_name  cache is 1 entries (29394160 bytes),  marked for eviction 0 entries (0 bytes).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331/622 [==============>...............] - ETA: 9s - loss: 1.4909 - accuracy: 0.4319"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 14:59:42.459849: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:437] TPU host compilation cache miss: cache_key(14759355675721243362), session_name()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334/622 [===============>..............] - ETA: 14s - loss: 1.4982 - accuracy: 0.4320"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 14:59:48.625944: I tensorflow/core/tpu/kernels/tpu_compile_op_common.cc:210] Compilation of 14759355675721243362 with session name  took 6.165977192s and succeeded\n",
      "2022-12-01 14:59:48.648131: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:470] TPU host compilation cache: compilation complete for cache_key(14759355675721243362), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_train_function_10405401112127002185\", property.function_library_fingerprint = 5401249623246154427, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, topology.MissingChipCount() = 0, std::string(property.shapes_prefix) = \"5,240,240,4,;5,;5,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\n",
      "2022-12-01 14:59:48.648189: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:536] After adding entry for key 14759355675721243362 with session_name  cache is 2 entries (63741493 bytes),  marked for eviction 0 entries (0 bytes).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - ETA: 0s - loss: 1.4156 - accuracy: 0.4661"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 14:59:58.172999: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_1\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_STRING\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 9945\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\024TensorSliceDataset:7\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"replicate_on_split\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_STRING\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "2022-12-01 15:00:00.961916: I tensorflow/core/tpu/graph_rewrite/encapsulate_tpu_computations_pass.cc:237] Subgraph fingerprint:1642185023948147569\n",
      "2022-12-01 15:00:01.105224: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n",
      "2022-12-01 15:00:01.324059: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n",
      "2022-12-01 15:00:01.815151: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:437] TPU host compilation cache miss: cache_key(11560650998618085540), session_name()\n",
      "2022-12-01 15:00:05.253537: I tensorflow/core/tpu/kernels/tpu_compile_op_common.cc:210] Compilation of 11560650998618085540 with session name  took 3.43826905s and succeeded\n",
      "2022-12-01 15:00:05.267970: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:470] TPU host compilation cache: compilation complete for cache_key(11560650998618085540), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_test_function_1642185023948147569\", property.function_library_fingerprint = 13316062128066535420, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, topology.MissingChipCount() = 0, std::string(property.shapes_prefix) = \"8,240,240,4,;8,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\n",
      "2022-12-01 15:00:05.268023: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:536] After adding entry for key 11560650998618085540 with session_name  cache is 3 entries (78212718 bytes),  marked for eviction 0 entries (0 bytes).\n",
      "2022-12-01 15:00:09.353919: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:437] TPU host compilation cache miss: cache_key(7645629890185120078), session_name()\n",
      "2022-12-01 15:00:12.975244: I tensorflow/core/tpu/kernels/tpu_compile_op_common.cc:210] Compilation of 7645629890185120078 with session name  took 3.621223634s and succeeded\n",
      "2022-12-01 15:00:12.989318: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:470] TPU host compilation cache: compilation complete for cache_key(7645629890185120078), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_test_function_1642185023948147569\", property.function_library_fingerprint = 13316062128066535420, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, topology.MissingChipCount() = 0, std::string(property.shapes_prefix) = \"4,240,240,4,;4,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\n",
      "2022-12-01 15:00:12.989380: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:536] After adding entry for key 7645629890185120078 with session_name  cache is 4 entries (92860427 bytes),  marked for eviction 0 entries (0 bytes).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 57s 67ms/step - loss: 1.4156 - accuracy: 0.4661 - val_loss: 1.0276 - val_accuracy: 0.6332\n",
      "Epoch 2/80\n",
      "622/622 [==============================] - 24s 39ms/step - loss: 1.2273 - accuracy: 0.5377 - val_loss: 1.0191 - val_accuracy: 0.6012\n",
      "Epoch 3/80\n",
      "622/622 [==============================] - 24s 39ms/step - loss: 1.1504 - accuracy: 0.5650 - val_loss: 1.0683 - val_accuracy: 0.5722\n",
      "Epoch 4/80\n",
      "622/622 [==============================] - 24s 38ms/step - loss: 1.1138 - accuracy: 0.5782 - val_loss: 1.0598 - val_accuracy: 0.5676\n",
      "Epoch 5/80\n",
      "622/622 [==============================] - 23s 37ms/step - loss: 1.0668 - accuracy: 0.5932 - val_loss: 1.0070 - val_accuracy: 0.5984\n",
      "Epoch 6/80\n",
      "622/622 [==============================] - 24s 38ms/step - loss: 1.0443 - accuracy: 0.5990 - val_loss: 0.9328 - val_accuracy: 0.6305\n",
      "Epoch 7/80\n",
      "622/622 [==============================] - 23s 37ms/step - loss: 1.0270 - accuracy: 0.6059 - val_loss: 0.9784 - val_accuracy: 0.5777\n",
      "Epoch 8/80\n",
      "622/622 [==============================] - 23s 37ms/step - loss: 1.0105 - accuracy: 0.6053 - val_loss: 0.8365 - val_accuracy: 0.6885\n",
      "Epoch 9/80\n",
      "622/622 [==============================] - 23s 37ms/step - loss: 0.9907 - accuracy: 0.6141 - val_loss: 0.8467 - val_accuracy: 0.6755\n",
      "Epoch 10/80\n",
      "622/622 [==============================] - 22s 36ms/step - loss: 0.9748 - accuracy: 0.6179 - val_loss: 0.9043 - val_accuracy: 0.6483\n",
      "Epoch 11/80\n",
      "622/622 [==============================] - 22s 36ms/step - loss: 0.9606 - accuracy: 0.6237 - val_loss: 0.8984 - val_accuracy: 0.6390\n",
      "Epoch 12/80\n",
      "622/622 [==============================] - 23s 36ms/step - loss: 0.9748 - accuracy: 0.6222 - val_loss: 0.8323 - val_accuracy: 0.6834\n",
      "Epoch 13/80\n",
      "622/622 [==============================] - 22s 36ms/step - loss: 0.9590 - accuracy: 0.6242 - val_loss: 0.8984 - val_accuracy: 0.6387\n",
      "Epoch 14/80\n",
      "622/622 [==============================] - 23s 37ms/step - loss: 0.9483 - accuracy: 0.6270 - val_loss: 0.8029 - val_accuracy: 0.6995\n",
      "Epoch 15/80\n",
      "622/622 [==============================] - 22s 36ms/step - loss: 0.9405 - accuracy: 0.6300 - val_loss: 0.8769 - val_accuracy: 0.6659\n",
      "Epoch 16/80\n",
      "622/622 [==============================] - 22s 36ms/step - loss: 0.9282 - accuracy: 0.6323 - val_loss: 0.8439 - val_accuracy: 0.6778\n",
      "Epoch 17/80\n",
      "622/622 [==============================] - 23s 37ms/step - loss: 0.9317 - accuracy: 0.6295 - val_loss: 0.9157 - val_accuracy: 0.6217\n",
      "Epoch 18/80\n",
      "622/622 [==============================] - 23s 38ms/step - loss: 0.9232 - accuracy: 0.6351 - val_loss: 0.8104 - val_accuracy: 0.6912\n",
      "Epoch 19/80\n",
      "622/622 [==============================] - 23s 36ms/step - loss: 0.9053 - accuracy: 0.6367 - val_loss: 0.8303 - val_accuracy: 0.6672\n",
      "Epoch 20/80\n",
      "622/622 [==============================] - 23s 36ms/step - loss: 0.9059 - accuracy: 0.6392 - val_loss: 0.9028 - val_accuracy: 0.6110\n",
      "Epoch 21/80\n",
      "622/622 [==============================] - 24s 38ms/step - loss: 0.8938 - accuracy: 0.6388 - val_loss: 0.7921 - val_accuracy: 0.6942\n",
      "Epoch 22/80\n",
      "622/622 [==============================] - 22s 36ms/step - loss: 0.9015 - accuracy: 0.6392 - val_loss: 0.8153 - val_accuracy: 0.6888\n",
      "Epoch 23/80\n",
      "622/622 [==============================] - 22s 36ms/step - loss: 0.8916 - accuracy: 0.6430 - val_loss: 0.8586 - val_accuracy: 0.6591\n",
      "Epoch 24/80\n",
      "622/622 [==============================] - 22s 36ms/step - loss: 0.8883 - accuracy: 0.6452 - val_loss: 0.8979 - val_accuracy: 0.6206\n",
      "Epoch 25/80\n",
      "622/622 [==============================] - 22s 36ms/step - loss: 0.8765 - accuracy: 0.6437 - val_loss: 0.8425 - val_accuracy: 0.6634\n",
      "Epoch 26/80\n",
      "622/622 [==============================] - 22s 36ms/step - loss: 0.8832 - accuracy: 0.6482 - val_loss: 0.9420 - val_accuracy: 0.5907\n",
      "Epoch 27/80\n",
      "622/622 [==============================] - 23s 36ms/step - loss: 0.8837 - accuracy: 0.6428 - val_loss: 0.8086 - val_accuracy: 0.6809\n",
      "Epoch 28/80\n",
      "622/622 [==============================] - 23s 36ms/step - loss: 0.8635 - accuracy: 0.6454 - val_loss: 0.8569 - val_accuracy: 0.6556\n",
      "Epoch 29/80\n",
      "622/622 [==============================] - 24s 39ms/step - loss: 0.8746 - accuracy: 0.6481 - val_loss: 0.8418 - val_accuracy: 0.6683\n",
      "Epoch 30/80\n",
      "622/622 [==============================] - 23s 36ms/step - loss: 0.8657 - accuracy: 0.6475 - val_loss: 0.8311 - val_accuracy: 0.6686\n",
      "Epoch 31/80\n",
      "622/622 [==============================] - 23s 36ms/step - loss: 0.8784 - accuracy: 0.6497 - val_loss: 0.8733 - val_accuracy: 0.6507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 15:11:55.491450: I tensorflow/core/tpu/graph_rewrite/encapsulate_tpu_computations_pass.cc:237] Subgraph fingerprint:1223823399348306813\n",
      "2022-12-01 15:11:55.613899: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n",
      "2022-12-01 15:11:55.799917: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n",
      "2022-12-01 15:11:56.074955: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:437] TPU host compilation cache miss: cache_key(13537918162263737921), session_name()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 15:11:59.278100: I tensorflow/core/tpu/kernels/tpu_compile_op_common.cc:210] Compilation of 13537918162263737921 with session name  took 3.203038711s and succeeded\n",
      "2022-12-01 15:11:59.290324: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:470] TPU host compilation cache: compilation complete for cache_key(13537918162263737921), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_predict_function_1223823399348306813\", property.function_library_fingerprint = 5452589718846498119, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, topology.MissingChipCount() = 0, std::string(property.shapes_prefix) = \"2,240,240,4,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\n",
      "2022-12-01 15:11:59.290384: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:536] After adding entry for key 13537918162263737921 with session_name  cache is 5 entries (105174152 bytes),  marked for eviction 0 entries (0 bytes).\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmptivl8ca7/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmptivl8ca7/model/data/model/assets\n",
      "2022/12/01 15:12:35 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during tensorflow autologging: Unable to locate credentials\n",
      "2022-12-01 15:12:36.153941: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_1\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_STRING\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 39780\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\024TensorSliceDataset:0\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"replicate_on_split\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_STRING\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "2022/12/01 15:12:36 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during autologging: Unable to locate credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 15:12:46.674300: I tensorflow/core/tpu/graph_rewrite/encapsulate_tpu_computations_pass.cc:237] Subgraph fingerprint:8398881911490627436\n",
      "2022-12-01 15:12:47.262515: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/Adam/AssignAddVariableOp.\n",
      "2022-12-01 15:12:47.699151: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/Adam/AssignAddVariableOp.\n",
      "2022-12-01 15:12:48.602267: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:437] TPU host compilation cache miss: cache_key(18224724656348430986), session_name()\n",
      "2022-12-01 15:12:58.498786: I tensorflow/core/tpu/kernels/tpu_compile_op_common.cc:210] Compilation of 18224724656348430986 with session name  took 9.896431936s and succeeded\n",
      "2022-12-01 15:12:58.525800: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:470] TPU host compilation cache: compilation complete for cache_key(18224724656348430986), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_train_function_8398881911490627436\", property.function_library_fingerprint = 12272595353200119753, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, topology.MissingChipCount() = 0, std::string(property.shapes_prefix) = \"8,240,240,4,;8,;8,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\n",
      "2022-12-01 15:12:58.525863: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:536] After adding entry for key 18224724656348430986 with session_name  cache is 6 entries (146928222 bytes),  marked for eviction 0 entries (0 bytes).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 49/622 [=>............................] - ETA: 28s - loss: 1.5108 - accuracy: 0.4490"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 15:13:01.328072: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:437] TPU host compilation cache miss: cache_key(13640172023995873860), session_name()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 53/622 [=>............................] - ETA: 2:00 - loss: 1.5345 - accuracy: 0.4444"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 15:13:09.671628: I tensorflow/core/tpu/kernels/tpu_compile_op_common.cc:210] Compilation of 13640172023995873860 with session name  took 8.343468443s and succeeded\n",
      "2022-12-01 15:13:09.706493: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:470] TPU host compilation cache: compilation complete for cache_key(13640172023995873860), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_train_function_8398881911490627436\", property.function_library_fingerprint = 12272595353200119753, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, topology.MissingChipCount() = 0, std::string(property.shapes_prefix) = \"5,240,240,4,;5,;5,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\n",
      "2022-12-01 15:13:09.706556: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:536] After adding entry for key 13640172023995873860 with session_name  cache is 7 entries (194202974 bytes),  marked for eviction 0 entries (0 bytes).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - ETA: 0s - loss: 1.2711 - accuracy: 0.5399"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 15:13:29.518000: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_1\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_STRING\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 9945\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\024TensorSliceDataset:7\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"replicate_on_split\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_STRING\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "2022-12-01 15:13:31.809891: I tensorflow/core/tpu/graph_rewrite/encapsulate_tpu_computations_pass.cc:237] Subgraph fingerprint:1642185023948147569\n",
      "2022-12-01 15:13:31.963385: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n",
      "2022-12-01 15:13:32.190816: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 59s 61ms/step - loss: 1.2711 - accuracy: 0.5399 - val_loss: 0.8269 - val_accuracy: 0.6812\n",
      "Epoch 33/130\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.9865 - accuracy: 0.6499 - val_loss: 0.8246 - val_accuracy: 0.6488\n",
      "Epoch 34/130\n",
      "622/622 [==============================] - 26s 41ms/step - loss: 0.9135 - accuracy: 0.6739 - val_loss: 0.7085 - val_accuracy: 0.7176\n",
      "Epoch 35/130\n",
      "622/622 [==============================] - 25s 39ms/step - loss: 0.8200 - accuracy: 0.7011 - val_loss: 0.7298 - val_accuracy: 0.6999\n",
      "Epoch 36/130\n",
      "622/622 [==============================] - 24s 39ms/step - loss: 0.7565 - accuracy: 0.7242 - val_loss: 0.6983 - val_accuracy: 0.7136\n",
      "Epoch 37/130\n",
      "622/622 [==============================] - 24s 39ms/step - loss: 0.7299 - accuracy: 0.7259 - val_loss: 0.5793 - val_accuracy: 0.7629\n",
      "Epoch 38/130\n",
      "622/622 [==============================] - 24s 39ms/step - loss: 0.6878 - accuracy: 0.7403 - val_loss: 0.5539 - val_accuracy: 0.7812\n",
      "Epoch 39/130\n",
      "622/622 [==============================] - 24s 39ms/step - loss: 0.5992 - accuracy: 0.7651 - val_loss: 0.5863 - val_accuracy: 0.7640\n",
      "Epoch 40/130\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.5672 - accuracy: 0.7763 - val_loss: 0.5960 - val_accuracy: 0.7472\n",
      "Epoch 41/130\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.5444 - accuracy: 0.7790 - val_loss: 0.5046 - val_accuracy: 0.8038\n",
      "Epoch 42/130\n",
      "622/622 [==============================] - 24s 39ms/step - loss: 0.5163 - accuracy: 0.7883 - val_loss: 0.5603 - val_accuracy: 0.7732\n",
      "Epoch 43/130\n",
      "622/622 [==============================] - 24s 39ms/step - loss: 0.4529 - accuracy: 0.8067 - val_loss: 0.5097 - val_accuracy: 0.7925\n",
      "Epoch 44/130\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.4129 - accuracy: 0.8196 - val_loss: 0.5146 - val_accuracy: 0.8023\n",
      "Epoch 45/130\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.3875 - accuracy: 0.8246 - val_loss: 0.4334 - val_accuracy: 0.8266\n",
      "Epoch 46/130\n",
      "622/622 [==============================] - 24s 39ms/step - loss: 0.3703 - accuracy: 0.8310 - val_loss: 0.4811 - val_accuracy: 0.8191\n",
      "Epoch 47/130\n",
      "622/622 [==============================] - 24s 39ms/step - loss: 0.3143 - accuracy: 0.8488 - val_loss: 0.4449 - val_accuracy: 0.8359\n",
      "Epoch 48/130\n",
      "622/622 [==============================] - 24s 39ms/step - loss: 0.2827 - accuracy: 0.8618 - val_loss: 0.4058 - val_accuracy: 0.8492\n",
      "Epoch 49/130\n",
      "622/622 [==============================] - 24s 39ms/step - loss: 0.2912 - accuracy: 0.8645 - val_loss: 0.4157 - val_accuracy: 0.8489\n",
      "Epoch 50/130\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.2284 - accuracy: 0.8835 - val_loss: 0.3928 - val_accuracy: 0.8629\n",
      "Epoch 51/130\n",
      "622/622 [==============================] - 25s 41ms/step - loss: 0.2256 - accuracy: 0.8857 - val_loss: 0.4609 - val_accuracy: 0.8437\n",
      "Epoch 52/130\n",
      "622/622 [==============================] - 24s 39ms/step - loss: 0.2228 - accuracy: 0.8889 - val_loss: 0.3847 - val_accuracy: 0.8580\n",
      "Epoch 53/130\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.2013 - accuracy: 0.8975 - val_loss: 0.3673 - val_accuracy: 0.8753\n",
      "Epoch 54/130\n",
      "622/622 [==============================] - 24s 39ms/step - loss: 0.1827 - accuracy: 0.9098 - val_loss: 0.3822 - val_accuracy: 0.8657\n",
      "Epoch 55/130\n",
      "622/622 [==============================] - 24s 39ms/step - loss: 0.2430 - accuracy: 0.8847 - val_loss: 0.4016 - val_accuracy: 0.8607\n",
      "Epoch 56/130\n",
      "622/622 [==============================] - 24s 39ms/step - loss: 0.2372 - accuracy: 0.8884 - val_loss: 0.3619 - val_accuracy: 0.8729\n",
      "Epoch 57/130\n",
      "622/622 [==============================] - 24s 39ms/step - loss: 0.1402 - accuracy: 0.9274 - val_loss: 0.3639 - val_accuracy: 0.8895\n",
      "Epoch 58/130\n",
      "622/622 [==============================] - 24s 39ms/step - loss: 0.1305 - accuracy: 0.9352 - val_loss: 0.3905 - val_accuracy: 0.8787\n",
      "Epoch 59/130\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.1164 - accuracy: 0.9411 - val_loss: 0.4746 - val_accuracy: 0.8712\n",
      "Epoch 60/130\n",
      "622/622 [==============================] - 24s 39ms/step - loss: 0.1120 - accuracy: 0.9444 - val_loss: 0.3918 - val_accuracy: 0.8890\n",
      "Epoch 61/130\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.1287 - accuracy: 0.9366 - val_loss: 0.3932 - val_accuracy: 0.8939\n",
      "Epoch 62/130\n",
      "622/622 [==============================] - 24s 39ms/step - loss: 0.1650 - accuracy: 0.9291 - val_loss: 0.5875 - val_accuracy: 0.7871\n",
      "Epoch 63/130\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.1689 - accuracy: 0.9223 - val_loss: 0.5916 - val_accuracy: 0.8131\n",
      "Epoch 64/130\n",
      "622/622 [==============================] - 24s 39ms/step - loss: 0.1008 - accuracy: 0.9506 - val_loss: 0.4073 - val_accuracy: 0.8896\n",
      "Epoch 65/130\n",
      "622/622 [==============================] - 24s 39ms/step - loss: 0.1066 - accuracy: 0.9494 - val_loss: 0.5093 - val_accuracy: 0.8615\n",
      "Epoch 66/130\n",
      "622/622 [==============================] - 24s 39ms/step - loss: 0.0791 - accuracy: 0.9606 - val_loss: 0.5258 - val_accuracy: 0.8667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 15:27:48.151941: I tensorflow/core/tpu/graph_rewrite/encapsulate_tpu_computations_pass.cc:237] Subgraph fingerprint:1223823399348306813\n",
      "2022-12-01 15:27:48.274884: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n",
      "2022-12-01 15:27:48.453579: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp2wbvfc3a/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp2wbvfc3a/model/data/model/assets\n",
      "2022/12/01 15:28:25 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during tensorflow autologging: Unable to locate credentials\n",
      "2022-12-01 15:28:26.448452: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_1\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_STRING\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 39780\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\024TensorSliceDataset:0\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"replicate_on_split\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_STRING\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "2022/12/01 15:28:26 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during autologging: Unable to locate credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 15:28:43.065571: I tensorflow/core/tpu/graph_rewrite/encapsulate_tpu_computations_pass.cc:237] Subgraph fingerprint:4437417191903188822\n",
      "2022-12-01 15:28:43.957930: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/Adam/AssignAddVariableOp.\n",
      "2022-12-01 15:28:44.535271: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/Adam/AssignAddVariableOp.\n",
      "2022-12-01 15:28:45.782103: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:437] TPU host compilation cache miss: cache_key(5571990506842326672), session_name()\n",
      "2022-12-01 15:28:58.335426: I tensorflow/core/tpu/kernels/tpu_compile_op_common.cc:210] Compilation of 5571990506842326672 with session name  took 12.553222374s and succeeded\n",
      "2022-12-01 15:28:58.382328: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:470] TPU host compilation cache: compilation complete for cache_key(5571990506842326672), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_train_function_4437417191903188822\", property.function_library_fingerprint = 2254077375692676269, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, topology.MissingChipCount() = 0, std::string(property.shapes_prefix) = \"8,240,240,4,;8,;8,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\n",
      "2022-12-01 15:28:58.382395: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:536] After adding entry for key 5571990506842326672 with session_name  cache is 8 entries (260209447 bytes),  marked for eviction 0 entries (0 bytes).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6/622 [..............................] - ETA: 45s - loss: 0.0796 - accuracy: 0.9609WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0693s vs `on_train_batch_end` time: 0.0842s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0693s vs `on_train_batch_end` time: 0.0842s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479/622 [======================>.......] - ETA: 6s - loss: 0.1614 - accuracy: 0.9281"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 15:29:21.129754: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:437] TPU host compilation cache miss: cache_key(16503135754554191190), session_name()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481/622 [======================>.......] - ETA: 10s - loss: 0.1612 - accuracy: 0.9282"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 15:29:34.851085: I tensorflow/core/tpu/kernels/tpu_compile_op_common.cc:210] Compilation of 16503135754554191190 with session name  took 13.721218781s and succeeded\n",
      "2022-12-01 15:29:34.893284: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:470] TPU host compilation cache: compilation complete for cache_key(16503135754554191190), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_train_function_4437417191903188822\", property.function_library_fingerprint = 2254077375692676269, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, topology.MissingChipCount() = 0, std::string(property.shapes_prefix) = \"5,240,240,4,;5,;5,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\n",
      "2022-12-01 15:29:34.893342: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:536] After adding entry for key 16503135754554191190 with session_name  cache is 9 entries (336077304 bytes),  marked for eviction 0 entries (0 bytes).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "621/622 [============================>.] - ETA: 0s - loss: 0.1537 - accuracy: 0.9306"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 15:29:41.317379: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_1\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_STRING\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 9945\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\024TensorSliceDataset:7\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"replicate_on_split\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_STRING\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "2022-12-01 15:29:44.265022: I tensorflow/core/tpu/graph_rewrite/encapsulate_tpu_computations_pass.cc:237] Subgraph fingerprint:1642185023948147569\n",
      "2022-12-01 15:29:44.410006: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n",
      "2022-12-01 15:29:44.627209: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 67: val_loss improved from inf to 0.38845, saving model to ../model_checkpoints/mobilenetv2_bs64_pat10_del0.001_dr0.25_lr0.0005_save-2022-12-01-14:58:29-067-0.3884.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model_checkpoints/mobilenetv2_bs64_pat10_del0.001_dr0.25_lr0.0005_save-2022-12-01-14:58:29-067-0.3884.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model_checkpoints/mobilenetv2_bs64_pat10_del0.001_dr0.25_lr0.0005_save-2022-12-01-14:58:29-067-0.3884.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 108s 124ms/step - loss: 0.1538 - accuracy: 0.9305 - val_loss: 0.3884 - val_accuracy: 0.8710\n",
      "Epoch 68/165\n",
      "621/622 [============================>.] - ETA: 0s - loss: 0.2599 - accuracy: 0.9003\n",
      "Epoch 68: val_loss did not improve from 0.38845\n",
      "622/622 [==============================] - 33s 53ms/step - loss: 0.2600 - accuracy: 0.9003 - val_loss: 0.5805 - val_accuracy: 0.7848\n",
      "Epoch 69/165\n",
      "622/622 [==============================] - ETA: 0s - loss: 0.4633 - accuracy: 0.8274\n",
      "Epoch 69: val_loss did not improve from 0.38845\n",
      "622/622 [==============================] - 32s 51ms/step - loss: 0.4633 - accuracy: 0.8274 - val_loss: 0.4616 - val_accuracy: 0.8329\n",
      "Epoch 70/165\n",
      "621/622 [============================>.] - ETA: 0s - loss: 0.2726 - accuracy: 0.8917\n",
      "Epoch 70: val_loss did not improve from 0.38845\n",
      "622/622 [==============================] - 32s 51ms/step - loss: 0.2726 - accuracy: 0.8917 - val_loss: 0.4442 - val_accuracy: 0.8410\n",
      "Epoch 71/165\n",
      "621/622 [============================>.] - ETA: 0s - loss: 0.2108 - accuracy: 0.9127\n",
      "Epoch 71: val_loss did not improve from 0.38845\n",
      "622/622 [==============================] - 31s 50ms/step - loss: 0.2108 - accuracy: 0.9126 - val_loss: 0.4630 - val_accuracy: 0.8423\n",
      "Epoch 72/165\n",
      "622/622 [==============================] - ETA: 0s - loss: 0.1395 - accuracy: 0.9363\n",
      "Epoch 72: val_loss improved from 0.38845 to 0.35885, saving model to ../model_checkpoints/mobilenetv2_bs64_pat10_del0.001_dr0.25_lr0.0005_save-2022-12-01-14:58:29-072-0.3589.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model_checkpoints/mobilenetv2_bs64_pat10_del0.001_dr0.25_lr0.0005_save-2022-12-01-14:58:29-072-0.3589.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model_checkpoints/mobilenetv2_bs64_pat10_del0.001_dr0.25_lr0.0005_save-2022-12-01-14:58:29-072-0.3589.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 59s 95ms/step - loss: 0.1395 - accuracy: 0.9363 - val_loss: 0.3589 - val_accuracy: 0.9006\n",
      "Epoch 73/165\n",
      "621/622 [============================>.] - ETA: 0s - loss: 0.1124 - accuracy: 0.9488\n",
      "Epoch 73: val_loss did not improve from 0.35885\n",
      "622/622 [==============================] - 32s 51ms/step - loss: 0.1126 - accuracy: 0.9487 - val_loss: 0.4310 - val_accuracy: 0.8799\n",
      "Epoch 74/165\n",
      "622/622 [==============================] - ETA: 0s - loss: 0.1036 - accuracy: 0.9526\n",
      "Epoch 74: val_loss did not improve from 0.35885\n",
      "622/622 [==============================] - 33s 54ms/step - loss: 0.1036 - accuracy: 0.9526 - val_loss: 0.5048 - val_accuracy: 0.8667\n",
      "Epoch 75/165\n",
      "621/622 [============================>.] - ETA: 0s - loss: 0.3625 - accuracy: 0.8598\n",
      "Epoch 75: val_loss did not improve from 0.35885\n",
      "622/622 [==============================] - 32s 51ms/step - loss: 0.3620 - accuracy: 0.8601 - val_loss: 0.4026 - val_accuracy: 0.8688\n",
      "Epoch 76/165\n",
      "621/622 [============================>.] - ETA: 0s - loss: 0.1798 - accuracy: 0.9258\n",
      "Epoch 76: val_loss did not improve from 0.35885\n",
      "622/622 [==============================] - 32s 52ms/step - loss: 0.1798 - accuracy: 0.9258 - val_loss: 0.3609 - val_accuracy: 0.8939\n",
      "Epoch 77/165\n",
      "622/622 [==============================] - ETA: 0s - loss: 0.1027 - accuracy: 0.9518\n",
      "Epoch 77: val_loss improved from 0.35885 to 0.33132, saving model to ../model_checkpoints/mobilenetv2_bs64_pat10_del0.001_dr0.25_lr0.0005_save-2022-12-01-14:58:29-077-0.3313.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model_checkpoints/mobilenetv2_bs64_pat10_del0.001_dr0.25_lr0.0005_save-2022-12-01-14:58:29-077-0.3313.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model_checkpoints/mobilenetv2_bs64_pat10_del0.001_dr0.25_lr0.0005_save-2022-12-01-14:58:29-077-0.3313.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 59s 94ms/step - loss: 0.1027 - accuracy: 0.9518 - val_loss: 0.3313 - val_accuracy: 0.9107\n",
      "Epoch 78/165\n",
      "621/622 [============================>.] - ETA: 0s - loss: 0.1139 - accuracy: 0.9478\n",
      "Epoch 78: val_loss did not improve from 0.33132\n",
      "622/622 [==============================] - 32s 51ms/step - loss: 0.1138 - accuracy: 0.9478 - val_loss: 0.4037 - val_accuracy: 0.8938\n",
      "Epoch 79/165\n",
      "622/622 [==============================] - ETA: 0s - loss: 0.2889 - accuracy: 0.8869\n",
      "Epoch 79: val_loss did not improve from 0.33132\n",
      "622/622 [==============================] - 31s 50ms/step - loss: 0.2889 - accuracy: 0.8869 - val_loss: 0.4380 - val_accuracy: 0.8512\n",
      "Epoch 80/165\n",
      "622/622 [==============================] - ETA: 0s - loss: 0.2080 - accuracy: 0.9144\n",
      "Epoch 80: val_loss did not improve from 0.33132\n",
      "622/622 [==============================] - 31s 50ms/step - loss: 0.2080 - accuracy: 0.9144 - val_loss: 0.4075 - val_accuracy: 0.8767\n",
      "Epoch 81/165\n",
      "622/622 [==============================] - ETA: 0s - loss: 0.1578 - accuracy: 0.9311\n",
      "Epoch 81: val_loss did not improve from 0.33132\n",
      "622/622 [==============================] - 31s 50ms/step - loss: 0.1578 - accuracy: 0.9311 - val_loss: 0.3659 - val_accuracy: 0.8919\n",
      "Epoch 82/165\n",
      "621/622 [============================>.] - ETA: 0s - loss: 0.1053 - accuracy: 0.9540\n",
      "Epoch 82: val_loss did not improve from 0.33132\n",
      "622/622 [==============================] - 31s 51ms/step - loss: 0.1053 - accuracy: 0.9540 - val_loss: 0.3476 - val_accuracy: 0.8973\n",
      "Epoch 83/165\n",
      "622/622 [==============================] - ETA: 0s - loss: 0.1011 - accuracy: 0.9534\n",
      "Epoch 83: val_loss did not improve from 0.33132\n",
      "622/622 [==============================] - 31s 50ms/step - loss: 0.1011 - accuracy: 0.9534 - val_loss: 0.3575 - val_accuracy: 0.9019\n",
      "Epoch 84/165\n",
      "621/622 [============================>.] - ETA: 0s - loss: 0.1194 - accuracy: 0.9474\n",
      "Epoch 84: val_loss did not improve from 0.33132\n",
      "622/622 [==============================] - 31s 50ms/step - loss: 0.1192 - accuracy: 0.9475 - val_loss: 0.3736 - val_accuracy: 0.8970\n",
      "Epoch 85/165\n",
      "621/622 [============================>.] - ETA: 0s - loss: 0.2773 - accuracy: 0.9022\n",
      "Epoch 85: val_loss did not improve from 0.33132\n",
      "622/622 [==============================] - 31s 50ms/step - loss: 0.2769 - accuracy: 0.9024 - val_loss: 0.3413 - val_accuracy: 0.8999\n",
      "Epoch 86/165\n",
      "622/622 [==============================] - ETA: 0s - loss: 0.0820 - accuracy: 0.9630\n",
      "Epoch 86: val_loss did not improve from 0.33132\n",
      "622/622 [==============================] - 33s 53ms/step - loss: 0.0820 - accuracy: 0.9630 - val_loss: 0.3689 - val_accuracy: 0.9083\n",
      "Epoch 87/165\n",
      "622/622 [==============================] - ETA: 0s - loss: 0.0802 - accuracy: 0.9633\n",
      "Epoch 87: val_loss did not improve from 0.33132\n",
      "622/622 [==============================] - 32s 52ms/step - loss: 0.0802 - accuracy: 0.9633 - val_loss: 0.3829 - val_accuracy: 0.8980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 15:41:56.776857: I tensorflow/core/tpu/graph_rewrite/encapsulate_tpu_computations_pass.cc:237] Subgraph fingerprint:1223823399348306813\n",
      "2022-12-01 15:41:56.945315: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n",
      "2022-12-01 15:41:57.173248: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp5oaye9l0/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp5oaye9l0/model/data/model/assets\n",
      "2022/12/01 15:42:35 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during tensorflow autologging: Unable to locate credentials\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with mlflow.start_run(\n",
    "    run_name=parent_run_name,\n",
    "    tags={\n",
    "        'dataset': dataset,\n",
    "    },\n",
    "    description=run_description,\n",
    "):\n",
    "\n",
    "    img_height = 240\n",
    "    img_width = 240\n",
    "    data_dir = os.path.join('..','data','UPENN-GBM','slice_classification_common_stratify','train')\n",
    "\n",
    "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        validation_split=0.2,\n",
    "        subset=\"training\",\n",
    "        color_mode=\"rgba\",\n",
    "        seed=RSEED,\n",
    "        image_size=(img_height, img_width),\n",
    "        batch_size=batch_size)\n",
    "\n",
    "    val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        validation_split=0.2,\n",
    "        subset=\"validation\",\n",
    "        color_mode=\"rgba\",\n",
    "        seed=RSEED,\n",
    "        image_size=(img_height, img_width),\n",
    "        batch_size=batch_size)\n",
    "\n",
    "    \n",
    "    class_names = train_ds.class_names\n",
    "\n",
    "    # Calculate class weights for weighting accuracy\n",
    "    ds_classes = []\n",
    "    for _, batch_classes in train_ds:\n",
    "        ds_classes.append(batch_classes.numpy())\n",
    "\n",
    "    ds_classes = np.concatenate(ds_classes)\n",
    "\n",
    "    class_weight = compute_class_weight(\n",
    "        class_weight = 'balanced',\n",
    "        classes = np.unique(ds_classes),\n",
    "        y=ds_classes\n",
    "    )\n",
    "\n",
    "    class_weight = dict(zip(np.unique(ds_classes), class_weight))\n",
    "\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "    train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "    val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    num_classes = len(class_names)\n",
    "    \n",
    "    margin = 8\n",
    "    scaled_height = img_height - 2*margin\n",
    "    scaled_width = img_width - 2*margin\n",
    "\n",
    "    # Build layers for model with fixed base\n",
    "    with strategy.scope():\n",
    "        crop_layer = tf.keras.layers.Cropping2D(margin)\n",
    "        rescale_initial = tf.keras.layers.Rescaling(1./127.5, offset=-1)\n",
    "        conv_4to3_channel = tf.keras.layers.Conv2D(3,1,padding='same',activation='tanh')\n",
    "        base_model = tf.keras.applications.MobileNetV2(\n",
    "            input_shape=(scaled_width,scaled_height,3),\n",
    "            include_top=False,\n",
    "            weights='imagenet'\n",
    "        )\n",
    "        global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        prediction_layer = tf.keras.layers.Dense(num_classes)\n",
    "\n",
    "        base_model.trainable = False\n",
    "        \n",
    "        inputs = tf.keras.Input(shape=(img_width, img_height, 4))\n",
    "        x = crop_layer(inputs)\n",
    "        x = rescale_initial(x)\n",
    "        x = conv_4to3_channel(x)\n",
    "        x = base_model(x, training=False)\n",
    "        x = global_average_layer(x)\n",
    "        x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "        outputs = prediction_layer(x)\n",
    "    \n",
    "        earlystopping = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=patience,\n",
    "            min_delta=min_delta,\n",
    "            )\n",
    "        \n",
    "        model = tf.keras.Model(inputs, outputs)\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=initial_learning_rate,),\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=['accuracy'],\n",
    "        )\n",
    "\n",
    "        \n",
    "    # Initial fit of classification and 4 to 3 channel layers\n",
    "    with mlflow.start_run(\n",
    "        run_name=f'fixed_{run_name_params}',\n",
    "        tags={'dataset': dataset},\n",
    "        nested=True\n",
    "    ):\n",
    "        mlflow.tensorflow.autolog()\n",
    "        mlflow.log_param('ds_batch_size', batch_size)\n",
    "        mlflow.log_param('ds_validation_batch_size', batch_size)\n",
    "\n",
    "\n",
    "        fixed_base_epochs=80\n",
    "        history_fixed_base = model.fit(\n",
    "            train_ds,\n",
    "            validation_data=val_ds,\n",
    "            epochs=fixed_base_epochs,\n",
    "            class_weight=class_weight,\n",
    "            callbacks=[earlystopping],\n",
    "        )\n",
    "\n",
    "    # Relax top layers of base model\n",
    "    base_model.trainable = True\n",
    "    fix_below_layer = 100\n",
    "    for layer in base_model.layers[:fix_below_layer]:\n",
    "        layer.trainable = False\n",
    "    with strategy.scope():\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=initial_learning_rate/10.0),\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'],\n",
    "        )\n",
    "\n",
    "    with mlflow.start_run(\n",
    "        run_name=f'partial_{run_name_params}',\n",
    "        tags={'dataset': dataset},\n",
    "        nested=True\n",
    "    ):\n",
    "        mlflow.tensorflow.autolog()\n",
    "        mlflow.log_param('ds_batch_size', batch_size)\n",
    "        mlflow.log_param('ds_validation_batch_size', batch_size)\n",
    "\n",
    "        partial_relax_epochs=history_fixed_base.epoch[-1] + 100 \n",
    "        history_partial_relax = model.fit(\n",
    "            train_ds,\n",
    "            validation_data=val_ds,\n",
    "            epochs=partial_relax_epochs,\n",
    "            initial_epoch=history_fixed_base.epoch[-1]+1,\n",
    "            class_weight=class_weight,\n",
    "            callbacks=[earlystopping],\n",
    "        )\n",
    "\n",
    "    # Fully relax model\n",
    "    model.trainable = True\n",
    "\n",
    "    with strategy.scope():\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=initial_learning_rate/10.0),\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=['accuracy'],\n",
    "        )\n",
    "\n",
    "    with mlflow.start_run(\n",
    "        run_name=f'relax_{run_name_params}',\n",
    "        tags={'dataset': dataset},\n",
    "        nested=True\n",
    "    ):\n",
    "        mlflow.tensorflow.autolog()\n",
    "        mlflow.log_param('ds_batch_size', batch_size)\n",
    "        mlflow.log_param('ds_validation_batch_size', batch_size)\n",
    "\n",
    "        # create checkpoint\n",
    "        checkpoint_path = os.path.join(\n",
    "            MODEL_CHECKPOINTS_DIR,\n",
    "            parent_run_name + start_time + \"-{epoch:03d}-{val_loss:.4f}.ckpt\"\n",
    "        )\n",
    "        ckpt_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=checkpoint_path, \n",
    "            verbose=1, \n",
    "            save_weights_only=False,\n",
    "            save_freq='epoch',\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            save_best_only=True,\n",
    "        ) \n",
    "\n",
    "        full_relax_epochs=history_partial_relax.epoch[-1] + 100\n",
    "        history_full_relax = model.fit(\n",
    "            train_ds,\n",
    "            validation_data=val_ds,\n",
    "            epochs=full_relax_epochs,\n",
    "            initial_epoch=history_partial_relax.epoch[-1]+1,\n",
    "            class_weight=class_weight,\n",
    "            callbacks=[earlystopping, ckpt_callback],\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9605 files belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data_dir = os.path.join('..','data','UPENN-GBM','slice_classification_common_stratify','test')\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_data_dir,\n",
    "    color_mode=\"rgba\",\n",
    "    seed=RSEED,\n",
    "    shuffle=False,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 15:42:36.696768: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_1\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_STRING\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 9945\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\024TensorSliceDataset:7\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"replicate_on_split\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_STRING\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "2022-12-01 15:42:38.899589: I tensorflow/core/tpu/graph_rewrite/encapsulate_tpu_computations_pass.cc:237] Subgraph fingerprint:6174737307138202066\n",
      "2022-12-01 15:42:39.033979: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n",
      "2022-12-01 15:42:39.245154: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n",
      "2022-12-01 15:42:39.589835: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:437] TPU host compilation cache miss: cache_key(13856037510993769846), session_name()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3/156 [..............................] - ETA: 12s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 15:42:43.046112: I tensorflow/core/tpu/kernels/tpu_compile_op_common.cc:210] Compilation of 13856037510993769846 with session name  took 3.456192188s and succeeded\n",
      "2022-12-01 15:42:43.058229: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:470] TPU host compilation cache: compilation complete for cache_key(13856037510993769846), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_predict_function_6174737307138202066\", property.function_library_fingerprint = 3681382967468109196, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, topology.MissingChipCount() = 0, std::string(property.shapes_prefix) = \"8,240,240,4,;8,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\n",
      "2022-12-01 15:42:43.058293: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:536] After adding entry for key 13856037510993769846 with session_name  cache is 10 entries (349449263 bytes),  marked for eviction 0 entries (0 bytes).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154/156 [============================>.] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 15:42:47.752907: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:437] TPU host compilation cache miss: cache_key(4278150416744106827), session_name()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156/156 [==============================] - 15s 53ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 15:42:51.232946: I tensorflow/core/tpu/kernels/tpu_compile_op_common.cc:210] Compilation of 4278150416744106827 with session name  took 3.479903897s and succeeded\n",
      "2022-12-01 15:42:51.246690: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:470] TPU host compilation cache: compilation complete for cache_key(4278150416744106827), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_predict_function_6174737307138202066\", property.function_library_fingerprint = 3681382967468109196, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, topology.MissingChipCount() = 0, std::string(property.shapes_prefix) = \"4,240,240,4,;4,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\n",
      "2022-12-01 15:42:51.246741: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:536] After adding entry for key 4278150416744106827 with session_name  cache is 11 entries (363071183 bytes),  marked for eviction 0 entries (0 bytes).\n"
     ]
    }
   ],
   "source": [
    "val_pred = model.predict(val_ds)\n",
    "val_prob = tf.nn.softmax(val_pred)\n",
    "val_class_pred = [np.argmax(x) for x in val_prob]\n",
    "val_base = [ 0 for x in val_class_pred ]\n",
    "\n",
    "val_true_class = []\n",
    "for _, classes in val_ds:\n",
    "    val_true_class += list(classes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 15:42:55.980996: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_1\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_STRING\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 9605\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\027TensorSliceDataset:7331\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"replicate_on_split\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_STRING\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/151 [============================>.] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 15:43:01.844077: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:437] TPU host compilation cache miss: cache_key(9312899852912686474), session_name()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 9s 56ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 15:43:05.217598: I tensorflow/core/tpu/kernels/tpu_compile_op_common.cc:210] Compilation of 9312899852912686474 with session name  took 3.37341895s and succeeded\n",
      "2022-12-01 15:43:05.231411: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:470] TPU host compilation cache: compilation complete for cache_key(9312899852912686474), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_predict_function_6174737307138202066\", property.function_library_fingerprint = 3681382967468109196, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, topology.MissingChipCount() = 0, std::string(property.shapes_prefix) = \"2,240,240,4,;2,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\n",
      "2022-12-01 15:43:05.231462: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:536] After adding entry for key 9312899852912686474 with session_name  cache is 12 entries (375389544 bytes),  marked for eviction 0 entries (0 bytes).\n"
     ]
    }
   ],
   "source": [
    "test_pred = model.predict(test_ds)\n",
    "test_prob = tf.nn.softmax(test_pred)\n",
    "test_class_pred = [np.argmax(x) for x in test_prob]\n",
    "test_base = [ 0 for x in test_class_pred ]\n",
    "\n",
    "test_true_class = []\n",
    "for _, classes in test_ds:\n",
    "    test_true_class += list(classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93      3082\n",
      "           1       0.90      0.80      0.85      2440\n",
      "           2       0.37      0.64      0.47       303\n",
      "           3       0.65      0.69      0.67        59\n",
      "           4       0.98      0.92      0.95      4061\n",
      "\n",
      "    accuracy                           0.90      9945\n",
      "   macro avg       0.76      0.81      0.77      9945\n",
      "weighted avg       0.91      0.90      0.90      9945\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(val_true_class, val_class_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      5708\n",
      "           1       0.71      0.67      0.69      1361\n",
      "           2       0.20      0.36      0.25       166\n",
      "           3       0.00      0.00      0.00        69\n",
      "           4       0.95      0.91      0.93      2301\n",
      "\n",
      "    accuracy                           0.88      9605\n",
      "   macro avg       0.56      0.58      0.56      9605\n",
      "weighted avg       0.89      0.88      0.88      9605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_true_class, test_class_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/mobilenetv2_bs64_pat10_del0.001_dr0.25_lr0.0005_save-2022-12-01-14:58:29/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/mobilenetv2_bs64_pat10_del0.001_dr0.25_lr0.0005_save-2022-12-01-14:58:29/assets\n"
     ]
    }
   ],
   "source": [
    "model_file_name = os.path.join(MODELS_DIR, parent_run_name + start_time)\n",
    "model.save(model_file_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
