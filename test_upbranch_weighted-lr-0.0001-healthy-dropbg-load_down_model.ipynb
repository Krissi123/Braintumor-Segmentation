{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "\n",
    "from modules.scandata import MriScan, MriSlice, TumourSegmentation, ScanType, ScanPlane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "#import tensorflow_datasets as tfds\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_logical_devices('TPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='local')\n",
    "tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
    "tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
    "strategy = tf.distribute.TPUStrategy(cluster_resolver)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "buffer_size = 1000\n",
    "img_height = 240\n",
    "img_width = 240\n",
    "data_dir = os.path.join('data','UPENN-GBM','slice_classification_common_stratify_healthysegmented','train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    color_mode=\"rgba\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    color_mode=\"rgba\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Calculate class weights ofr weighting accuracy\n",
    "ds_classes = []\n",
    "for _, batch_classes in train_ds:\n",
    "    ds_classes.append(batch_classes.numpy())\n",
    "\n",
    "ds_classes = np.concatenate(ds_classes)\n",
    "\n",
    "class_weight = compute_class_weight(\n",
    "    class_weight = 'balanced',\n",
    "    classes = np.unique(ds_classes),\n",
    "    y=ds_classes\n",
    ")\n",
    "\n",
    "class_weight = dict(zip(np.unique(ds_classes), class_weight))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = layers.Rescaling(1./(2**8-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = 8\n",
    "scaled_height = img_height - 2*margin\n",
    "scaled_width = img_width - 2*margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved model\n",
    "with strategy.scope():\n",
    "    trained_down_model = tf.keras.models.load_model('models/mobilenetv2_bs16_pat5_del0.001_dr0.25_lr0.0001_save-2022-12-02-09:29:15')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_test_batch_ims, val_test_batch_true_classes = next(iter(val_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = trained_down_model.predict(val_test_batch_ims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "val_test_probs = tf.nn.softmax(val_preds)\n",
    "val_pred_class = [np.argmax(x) for x in val_test_probs]\n",
    "print(classification_report(val_test_batch_true_classes, val_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    # Use the activations of these layers\n",
    "    pretrained_layer_name='mobilenetv2_1.00_224'\n",
    "    layer_names = [\n",
    "        'block_1_expand_relu',   # 64x64\n",
    "        'block_3_expand_relu',   # 32x32\n",
    "        'block_6_expand_relu',   # 16x16\n",
    "        'block_13_expand_relu',  # 8x8\n",
    "        'block_16_project',      # 4x4\n",
    "    ]\n",
    "    base_model_outputs = [\n",
    "        trained_down_model.get_layer(pretrained_layer_name)\n",
    "        .get_layer(name).output for name in layer_names\n",
    "    ]\n",
    "\n",
    "    # Create the feature extraction model\n",
    "    down_stack = tf.keras.Model(\n",
    "        inputs=trained_down_model.get_layer(pretrained_layer_name).input, \n",
    "        outputs=base_model_outputs\n",
    "    )\n",
    "\n",
    "    down_stack.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_stack.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(down_stack, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define each layer block for upbranch\n",
    "def upsample(filters, size, norm_type='batchnorm', apply_dropout=False):\n",
    "  \"\"\"Upsamples an input.\n",
    "\n",
    "  Conv2DTranspose => Batchnorm => Dropout => Relu\n",
    "\n",
    "  Args:\n",
    "    filters: number of filters\n",
    "    size: filter size\n",
    "    norm_type: Normalization type; either 'batchnorm' or 'instancenorm'.\n",
    "    apply_dropout: If True, adds the dropout layer\n",
    "\n",
    "  Returns:\n",
    "    Upsample Sequential Model\n",
    "  \"\"\"\n",
    "\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "  result = tf.keras.Sequential()\n",
    "  result.add(\n",
    "      tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
    "                                      padding='same',\n",
    "                                      kernel_initializer=initializer,\n",
    "                                      use_bias=False))\n",
    "\n",
    "  if norm_type.lower() == 'batchnorm':\n",
    "    result.add(tf.keras.layers.BatchNormalization())\n",
    "  #elif norm_type.lower() == 'instancenorm':\n",
    "  #  result.add(InstanceNormalization())\n",
    "\n",
    "  if apply_dropout:\n",
    "    result.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "  result.add(tf.keras.layers.ReLU())\n",
    "\n",
    "  return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_stack = [\n",
    "    upsample(512, 3),  # 7x7 -> 14x14\n",
    "    upsample(256, 3),  # 14x14 -> 28x28\n",
    "    upsample(128, 3),  # 28x28 -> 56x56\n",
    "    upsample(64, 3),   # 56x56 -> 112x112\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in trained_down_model.layers[1:4]:\n",
    "    print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model(output_channels: int):\n",
    "\n",
    "    # Add layers from classification model\n",
    "    inputs = tf.keras.layers.Input(shape=[240, 240, 4])\n",
    "    x = trained_down_model.layers[1](inputs)\n",
    "    for layer in trained_down_model.layers[2:4]:\n",
    "        x = layer(x)\n",
    "\n",
    "    # Downsampling through the model\n",
    "    skips = down_stack(x)\n",
    "    x = skips[-1]\n",
    "    skips = reversed(skips[:-1])\n",
    "\n",
    "    # Upsampling and establishing the skip connections\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        concat = tf.keras.layers.Concatenate()\n",
    "        x = concat([x, skip])\n",
    "\n",
    "    # This is the last layer of the model\n",
    "    last_conv_trans = tf.keras.layers.Conv2DTranspose(\n",
    "        filters=output_channels, kernel_size=3, strides=2, padding=\"same\"\n",
    "    )  # 64x64 -> 128x128\n",
    "\n",
    "    x = last_conv_trans(x)\n",
    "\n",
    "    x = tf.keras.layers.ZeroPadding2D(8)(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CLASSES = 5\n",
    "with strategy.scope():\n",
    "    model = unet_model(output_channels=OUTPUT_CLASSES)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00005,),\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colour_list = [[1,1,1], [1,0,0], [0,1,0], [0,0,1], [0,0,0]]\n",
    "colour_list = ['w', '#d73027', '#91bfdb', '0.8', '#fee090']\n",
    "cmap = ListedColormap(colour_list)\n",
    "\n",
    "def display(display_list):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.utils.array_to_img(display_list[i]),cmap=cmap)\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "  \n",
    "def create_mask(pred_mask):\n",
    "    pred_mask = tf.math.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    return pred_mask[0]\n",
    "\n",
    "def show_predictions(dataset=None, num=1):\n",
    "    if dataset:\n",
    "        for image, mask in dataset.take(num):\n",
    "            pred_mask = model.predict(image)\n",
    "        display([image[0], mask[0], create_mask(pred_mask)])\n",
    "    else:\n",
    "        display([sample_image, sample_mask,\n",
    "            create_mask(model.predict(sample_image[tf.newaxis, ...]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "maps = []\n",
    "\n",
    "train_image_dir = os.path.join('data','UPENN-GBM','slice_segmentation_stratify_healthy_dropbg','train','image_data')\n",
    "train_map_dir = os.path.join('data','UPENN-GBM','slice_segmentation_stratify_healthy_dropbg','train','map_data')\n",
    "\n",
    "# Count pixels for sample weight\n",
    "pixel_counts = [0,0,0,0,0]\n",
    "for map_file in os.listdir(train_map_dir):\n",
    "\n",
    "    seg_map = tf.io.read_file(os.path.join(train_map_dir,map_file))\n",
    "    seg_map = tf.io.decode_png(seg_map, channels=1)\n",
    "    \n",
    "    indices,counts = np.unique(seg_map,return_counts=True)\n",
    "    for i, index in enumerate(indices):\n",
    "        pixel_counts[index] += counts[i]\n",
    "print(pixel_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filenames = os.listdir(train_image_dir)\n",
    "map_filenames = [filename.replace('allseq', 'map') for filename in image_filenames]\n",
    "image_filepaths = [os.path.join(train_image_dir,filename) for filename in image_filenames]\n",
    "map_filepaths = [os.path.join(train_map_dir,filename) for filename in map_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_filepaths, val_image_filepaths, train_map_filepaths, val_map_filepaths = train_test_split(\n",
    "    image_filepaths, \n",
    "    map_filepaths, \n",
    "    test_size=0.2,\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_data = tf.data.Dataset.list_files(train_image_filepaths, shuffle=False)\n",
    "train_map_data = tf.data.Dataset.list_files(train_map_filepaths, shuffle=False)\n",
    "train_data = tf.data.Dataset.zip((train_image_data, train_map_data))\n",
    "val_image_data = tf.data.Dataset.list_files(val_image_filepaths, shuffle=False)\n",
    "val_map_data = tf.data.Dataset.list_files(val_map_filepaths, shuffle=False)\n",
    "val_data = tf.data.Dataset.zip((val_image_data, val_map_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaler_0_1(x):\n",
    "    return x/255.0\n",
    "\n",
    "def scaler_neg1_1(x):\n",
    "    return x/127.5 - 1\n",
    "\n",
    "def alter_segmap(x):\n",
    "    return tf.where(x==4,tf.constant(3,dtype='uint8'),x)\n",
    "\n",
    "def read_image_map(image, seg_map):\n",
    "   image = tf.io.read_file(image)\n",
    "   image = tf.io.decode_png(image, channels=4)\n",
    "   seg_map = tf.io.read_file(seg_map)\n",
    "   seg_map = tf.io.decode_png(seg_map, channels=1)\n",
    "   # Change scaler below to scaler_0_1 to get initial values between 0 and 1\n",
    "   return scaler_neg1_1(tf.cast(image, 'float32')), seg_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch = (\n",
    "    train_data.cache()\n",
    "    .shuffle(buffer_size)\n",
    "    .map(read_image_map)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")\n",
    "val_batch = val_data.map(read_image_map).shuffle(buffer_size).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, masks = next(iter(train_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 20\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(tf.cast(127.5*(images[num]+1), 'uint8'))\n",
    "ax[1].imshow(masks[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images, val_masks = next(iter(train_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnum = 7\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(tf.cast(127.5*(val_images[vnum]+1), 'uint8'))\n",
    "ax[1].imshow(val_masks[vnum])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, masks in train_batch.take(1):\n",
    "    sample_image, sample_mask = images[0], masks[0]\n",
    "    display([sample_image, sample_mask])\n",
    "    print(images.shape, masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_num=3\n",
    "sample_image, sample_mask = images[slice_num], masks[slice_num]\n",
    "show_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(sample_mask, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        clear_output(wait=True)\n",
    "        show_predictions()\n",
    "        print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weights\n",
    "weights = 1.0/np.array(pixel_counts)\n",
    "weights = weights/np.sum(weights)\n",
    "\n",
    "def add_sample_weights(image, label):\n",
    "  # The weights for each class, with the constraint that:\n",
    "  #     sum(class_weights) == 1.0\n",
    "  #class_weights = tf.constant([2.0, 2.0, 1.0])\n",
    "  #class_weights = class_weights/tf.reduce_sum(class_weights)\n",
    "\n",
    "  # Create an image of `sample_weights` by using the label at each pixel as an \n",
    "  # index into the `class weights` .\n",
    "  sample_weights = tf.gather(weights, indices=tf.cast(label, tf.int32))\n",
    "\n",
    "  return image, label, sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=3,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_image_filepaths),len(val_image_filepaths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr 0.0001\n",
    "TRAIN_LENGTH=61772\n",
    "EPOCHS = 40\n",
    "VAL_SUBSPLITS = 5\n",
    "VALIDATION_STEPS = 15443//batch_size//VAL_SUBSPLITS\n",
    "STEPS_PER_EPOCH = TRAIN_LENGTH // batch_size\n",
    "\n",
    "model_history = model.fit(\n",
    "    train_batch.map(add_sample_weights), \n",
    "    epochs=EPOCHS,\n",
    "    validation_steps=VALIDATION_STEPS,\n",
    "    validation_data=val_batch,\n",
    "    callbacks=[DisplayCallback(), earlystopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images, val_maps = next(iter(val_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(val_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_maps.shape\n",
    "plt.imshow(tf.cast(val_maps[48,:,:,0],'uint8'), cmap='terrain_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_img = tf.expand_dims(val_images[57],0)\n",
    "single_map = tf.expand_dims(val_maps[57],0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_ds = tf.data.Dataset.from_tensor_slices(([single_img],[single_map]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predictions(single_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully relax model\n",
    "model.trainable = True\n",
    "\n",
    "with strategy.scope():\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001,),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history_fullrelax = model.fit(\n",
    "    train_batch.map(add_sample_weights), \n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    initial_epoch=model_history.epoch[-1]+1,\n",
    "    validation_steps=VALIDATION_STEPS,\n",
    "    validation_data=val_batch,\n",
    "    callbacks=[DisplayCallback(), earlystopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predictions(single_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
