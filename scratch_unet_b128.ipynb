{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "from PIL import Image \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "\n",
    "from modules.scandata import MriScan, MriSlice, TumourSegmentation, ScanType, ScanPlane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "#import tensorflow_datasets as tfds\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from IPython.display import clear_output\n",
    "RSEED=123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_logical_devices('TPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='local')\n",
    "tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
    "tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
    "strategy = tf.distribute.TPUStrategy(cluster_resolver)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now().strftime('-%Y-%m-%d-%T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "buffer_size = 1000\n",
    "img_height = 240\n",
    "img_width = 240\n",
    "scan_channels = 4\n",
    "output_classes = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colour_list = ['w', '#d73027', '#91bfdb', '0.8', '#fee090']\n",
    "cmap = ListedColormap(colour_list)\n",
    "\n",
    "def display(display_list):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.utils.array_to_img(display_list[i]),cmap=cmap)\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "  \n",
    "def create_mask(pred_mask):\n",
    "    pred_mask = tf.math.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    return pred_mask[0]\n",
    "\n",
    "def show_predictions(dataset=None, num=1):\n",
    "    if dataset:\n",
    "        for image, mask in dataset.take(num):\n",
    "            pred_mask = model.predict(image)\n",
    "        display([image[0], mask[0], create_mask(pred_mask)])\n",
    "    else:\n",
    "        display([sample_image, sample_mask,\n",
    "            create_mask(model.predict(sample_image[tf.newaxis, ...]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "maps = []\n",
    "\n",
    "train_image_dir = os.path.join('data','UPENN-GBM','slice_segmentation_stratify_healthy_dropbg','train','image_data')\n",
    "train_map_dir = os.path.join('data','UPENN-GBM','slice_segmentation_stratify_healthy_dropbg','train','map_data')\n",
    "\n",
    "# Count pixels for sample weight\n",
    "pixel_counts = [0,0,0,0,0]\n",
    "for map_file in os.listdir(train_map_dir):\n",
    "\n",
    "    seg_map = tf.io.read_file(os.path.join(train_map_dir,map_file))\n",
    "    seg_map = tf.io.decode_png(seg_map, channels=1)\n",
    "    \n",
    "    indices,counts = np.unique(seg_map,return_counts=True)\n",
    "    for i, index in enumerate(indices):\n",
    "        pixel_counts[index] += counts[i]\n",
    "print(pixel_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filenames = os.listdir(train_image_dir)\n",
    "map_filenames = [filename.replace('allseq', 'map') for filename in image_filenames]\n",
    "image_filepaths = [os.path.join(train_image_dir,filename) for filename in image_filenames]\n",
    "map_filepaths = [os.path.join(train_map_dir,filename) for filename in map_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_filepaths, val_image_filepaths, train_map_filepaths, val_map_filepaths = train_test_split(\n",
    "    image_filepaths, \n",
    "    map_filepaths, \n",
    "    test_size=0.2,\n",
    "    random_state=RSEED,\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_data = tf.data.Dataset.list_files(train_image_filepaths, shuffle=False)\n",
    "train_map_data = tf.data.Dataset.list_files(train_map_filepaths, shuffle=False)\n",
    "train_data = tf.data.Dataset.zip((train_image_data, train_map_data))\n",
    "val_image_data = tf.data.Dataset.list_files(val_image_filepaths, shuffle=False)\n",
    "val_map_data = tf.data.Dataset.list_files(val_map_filepaths, shuffle=False)\n",
    "val_data = tf.data.Dataset.zip((val_image_data, val_map_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaler_0_1(x):\n",
    "    return x/255.0\n",
    "\n",
    "def scaler_neg1_1(x):\n",
    "    return x/127.5 - 1\n",
    "\n",
    "def alter_segmap(x):\n",
    "    return tf.where(x==4,tf.constant(3,dtype='uint8'),x)\n",
    "\n",
    "def read_image_map(image, seg_map):\n",
    "   image = tf.io.read_file(image)\n",
    "   image = tf.io.decode_png(image, channels=4)\n",
    "   seg_map = tf.io.read_file(seg_map)\n",
    "   seg_map = tf.io.decode_png(seg_map, channels=1)\n",
    "   # Change scaler below to scaler_0_1 to get initial values between 0 and 1\n",
    "   return scaler_neg1_1(tf.cast(image, 'float32')) ,seg_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch = (\n",
    "    train_data.cache()\n",
    "    .shuffle(buffer_size, seed=tf.constant(RSEED,dtype='int64'))\n",
    "    .repeat()\n",
    "    .map(read_image_map)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")\n",
    "val_batch = (\n",
    "    val_data\n",
    "    .shuffle(buffer_size, seed=tf.constant(RSEED,dtype='int64'))\n",
    "    .map(read_image_map)\n",
    "    .batch(batch_size),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images, val_masks = next(iter(train_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnum = 7\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(tf.cast(127.5*(val_images[vnum]+1), 'uint8'))\n",
    "ax[1].imshow(val_masks[vnum])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weights\n",
    "weights = 1.0/np.array(pixel_counts)\n",
    "weights = weights/np.sum(weights)\n",
    "\n",
    "def add_sample_weights(image, label):\n",
    "  # The weights for each class, with the constraint that:\n",
    "  #     sum(class_weights) == 1.0\n",
    "  #class_weights = tf.constant([2.0, 2.0, 1.0])\n",
    "  #class_weights = class_weights/tf.reduce_sum(class_weights)\n",
    "\n",
    "  # Create an image of `sample_weights` by using the label at each pixel as an \n",
    "  # index into the `class weights` .\n",
    "  sample_weights = tf.gather(weights, indices=tf.cast(label, tf.int32))\n",
    "\n",
    "  return image, label, sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define convolution layer steps\n",
    "initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "def horizontal_convolution(input, num_filters, activation='relu', dropout_rate=0.0):\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        filters=num_filters,\n",
    "        kernel_size=3,\n",
    "        padding= 'same',\n",
    "        strides=1,\n",
    "        kernel_initializer=initializer,\n",
    "        use_bias=False,\n",
    "    )(input)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(rate=dropout_rate)(x)\n",
    "    x = tf.keras.layers.Activation(activation=activation)(x) \n",
    "    return x\n",
    "\n",
    "\n",
    "def down_step(input, num_filters, dropout_rate=0.0):\n",
    "    x = horizontal_convolution(\n",
    "        input=input,\n",
    "        num_filters=num_filters,\n",
    "        dropout_rate=dropout_rate,\n",
    "    )\n",
    "    horizontal_out = horizontal_convolution(\n",
    "        x, \n",
    "        num_filters=num_filters,\n",
    "        dropout_rate=dropout_rate,\n",
    "    )\n",
    "    down_out = tf.keras.layers.MaxPooling2D(\n",
    "        pool_size=2,\n",
    "        strides=2, \n",
    "        padding = 'same'\n",
    "    )(horizontal_out)\n",
    "    return down_out, horizontal_out\n",
    "\n",
    "\n",
    "def up_step(\n",
    "    up_input, \n",
    "    horizontal_input, \n",
    "    num_filters, \n",
    "    dropout_rate=0.0, \n",
    "):\n",
    "    x = tf.keras.layers.Conv2DTranspose(\n",
    "        filters=num_filters,\n",
    "        kernel_size=3, \n",
    "        strides=2,\n",
    "        padding='same',\n",
    "        kernel_initializer=initializer,\n",
    "        use_bias=False,\n",
    "    )(up_input)\n",
    "    x = tf.keras.layers.Concatenate()([x, horizontal_input])\n",
    "    x = horizontal_convolution(\n",
    "        x, \n",
    "        num_filters=num_filters, \n",
    "        dropout_rate=dropout_rate\n",
    "    )\n",
    "    x = horizontal_convolution(\n",
    "        x, \n",
    "        num_filters=num_filters, \n",
    "        dropout_rate=dropout_rate,\n",
    "        activation='softmax',\n",
    "    )\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define U-Net topology\n",
    "def unet(\n",
    "    input_shape, \n",
    "    output_channels, \n",
    "    scale_filters=1.0, \n",
    "    dropout_rate=0.0,\n",
    "    final_dropout=True\n",
    "    ):\n",
    "\n",
    "    final_dropout_rate=0.0\n",
    "    if final_dropout:\n",
    "        final_dropout_rate = dropout_rate\n",
    "\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "\n",
    "    down_1, cross_1 = down_step(\n",
    "        inputs, \n",
    "        int(64*scale_filters), \n",
    "        dropout_rate=dropout_rate\n",
    "    )  # 240 -> 120\n",
    "    down_2, cross_2 = down_step(\n",
    "        down_1, \n",
    "        int(128*scale_filters), \n",
    "        dropout_rate=dropout_rate\n",
    "    )  # 120 -> 60\n",
    "    down_3, cross_3 = down_step(\n",
    "        down_2, \n",
    "        int(256*scale_filters), \n",
    "        dropout_rate=dropout_rate\n",
    "    )  # 60 -> 30\n",
    "    down_4, cross_4 = down_step(\n",
    "        down_3, \n",
    "        int(512*scale_filters), \n",
    "        dropout_rate=dropout_rate\n",
    "    )  # 30 -> 15\n",
    "\n",
    "    bottom = horizontal_convolution(\n",
    "        down_4, \n",
    "        int(1024*scale_filters), \n",
    "        dropout_rate=dropout_rate\n",
    "    )\n",
    "\n",
    "    up_4 = up_step(\n",
    "        bottom, \n",
    "        cross_4, \n",
    "        int(512*scale_filters), \n",
    "        dropout_rate=dropout_rate\n",
    "    )  # 15 -> 30\n",
    "    up_3 = up_step(\n",
    "        up_4, \n",
    "        cross_3, \n",
    "        int(256*scale_filters), \n",
    "        dropout_rate=dropout_rate\n",
    "    )  # 30 -> 60\n",
    "    up_2 = up_step(\n",
    "        up_3, \n",
    "        cross_2, \n",
    "        int(128*scale_filters), \n",
    "        dropout_rate=dropout_rate\n",
    "    )  # 60 -> 120\n",
    "    up_1 = up_step(\n",
    "        up_2, \n",
    "        cross_1, \n",
    "        int(64*scale_filters), \n",
    "        dropout_rate=final_dropout_rate\n",
    "    )  # 120 -> 240\n",
    "    \n",
    "    outputs = horizontal_convolution(up_1, output_channels)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    input_shape = (img_width,img_height,scan_channels)\n",
    "    model = unet(\n",
    "        input_shape=input_shape, \n",
    "        output_channels=output_classes, \n",
    "        dropout_rate=0.0\n",
    "    )\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001,),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, masks in train_batch.take(1):\n",
    "    sample_image, sample_mask = images[0], masks[0]\n",
    "    display([sample_image, sample_mask])\n",
    "    print(images.shape, masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_num=17\n",
    "sample_image, sample_mask = images[slice_num], masks[slice_num]\n",
    "show_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        #clear_output(wait=True)\n",
    "        show_predictions()\n",
    "        print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name_params = (\n",
    "        f'bs64'\n",
    "        f'_pat10'\n",
    "        f'_dr0.0'\n",
    "        f'_lr0.0001'\n",
    "    )\n",
    "    \n",
    "print(\"Using parameters\")\n",
    "print(run_name_params)\n",
    "run_name = f'unet_{run_name_params}_scratch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('model_checkpoints'):\n",
    "    os.mkdir('model_checkpoints')\n",
    "\n",
    "checkpoint_path = os.path.join(\n",
    "    'model_checkpoints',\n",
    "    run_name + start_time + \"-{epoch:03d}-{val_loss:.4f}.ckpt\"\n",
    ")\n",
    "ckpt_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=1, \n",
    "    save_weights_only=False,\n",
    "    save_freq='epoch',\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_image_filepaths),len(val_image_filepaths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr 0.0001\n",
    "TRAIN_LENGTH=61772\n",
    "EPOCHS = 100\n",
    "VAL_SUBSPLITS = 1\n",
    "VALIDATION_STEPS = 15443//batch_size//VAL_SUBSPLITS\n",
    "STEPS_PER_EPOCH = TRAIN_LENGTH // batch_size\n",
    "\n",
    "model_history = model.fit(\n",
    "    train_batch.map(add_sample_weights), \n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    validation_steps=VALIDATION_STEPS,\n",
    "    validation_data=val_batch,\n",
    "    callbacks=[DisplayCallback(), earlystopping, ckpt_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_name = os.path.join('models', run_name + start_time)\n",
    "model.save(model_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images, val_maps = next(iter(val_batch[0].take(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(val_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_maps.shape\n",
    "num = 12\n",
    "plt.imshow(tf.cast(val_maps[num,:,:,0],'uint8'), cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_img = tf.expand_dims(val_images[num],0)\n",
    "single_map = tf.expand_dims(val_maps[num],0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_ds = tf.data.Dataset.from_tensor_slices(([single_img],[single_map]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predictions(single_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(model_history.epoch,model_history.history['val_loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(model_history.history['val_loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=5,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train layers below layer 100 in down branch\n",
    "model.layers[4].trainable = True\n",
    "for layer in model.layers[4].layers[:100]:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001,),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history_partialrelax = model.fit(\n",
    "    train_batch.map(add_sample_weights), \n",
    "    epochs=50,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    initial_epoch=model_history.epoch[-1]+1,\n",
    "    validation_steps=VALIDATION_STEPS,\n",
    "    validation_data=val_batch,\n",
    "    callbacks=[DisplayCallback(), earlystopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predictions(single_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all layers\n",
    "model.trainable = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.000005,),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_STEPS = 15443//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history_fullrelax = model.fit(\n",
    "    train_batch.map(add_sample_weights), \n",
    "    epochs=80,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    initial_epoch=model_history_partialrelax.epoch[-1]+1,\n",
    "    validation_steps=VALIDATION_STEPS,\n",
    "    validation_data=val_batch,\n",
    "    callbacks=[DisplayCallback(), earlystopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
