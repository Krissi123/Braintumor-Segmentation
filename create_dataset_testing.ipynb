{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "from PIL import Image \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "\n",
    "from modules.scandata import MriScan, MriSlice, TumourSegmentation, ScanType, ScanPlane\n",
    "\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "#from tensorflow.keras import layers\n",
    "#from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "maps = []\n",
    "\n",
    "train_image_dir = os.path.join('data','UPENN-GBM','slice_segmentation_stratify','train','image_data')\n",
    "train_map_dir = os.path.join('data','UPENN-GBM','slice_segmentation_stratify','train','map_data')\n",
    "for image_file in os.listdir(train_image_dir):\n",
    "    map_file = image_file.replace('allseq', 'map')\n",
    "    if not os.path.exists(os.path.join(train_map_dir,map_file)):\n",
    "        raise FileNotFoundError((image_file, map_file))\n",
    "\n",
    "    image = tf.io.read_file(os.path.join(train_image_dir,image_file))\n",
    "    image = tf.io.decode_png(image, channels=4)\n",
    "    map = tf.io.read_file(os.path.join(train_map_dir,map_file))\n",
    "    map = tf.io.decode_png(map, channels=1)\n",
    "\n",
    "    map = map.numpy()\n",
    "    # Convert map to make class integers contiguous\n",
    "    map[map==4] = 3\n",
    "    map = tf.convert_to_tensor(map)\n",
    "    images.append(image)\n",
    "    maps.append(map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, val_images, train_maps, val_maps = train_test_split(images, maps, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(10,4)\n",
    "fig.set_size_inches(12,36)\n",
    "skip=0\n",
    "for row in range(10):\n",
    "    axs[row][0].imshow(train_images[skip+row])\n",
    "    axs[row][1].imshow(train_maps[skip+row])\n",
    "    axs[row][2].imshow(val_images[skip+row])\n",
    "    axs[row][3].imshow(val_maps[skip+row]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_images = tf.convert_to_tensor(train_images)\n",
    "train_maps = tf.convert_to_tensor(train_maps)\n",
    "val_images = tf.convert_to_tensor(val_images)\n",
    "val_maps = tf.convert_to_tensor(val_maps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaler_0_1(x):\n",
    "    return x/255.0\n",
    "\n",
    "def scaler_neg1_1(x):\n",
    "    return x/127.5 - 1\n",
    "\n",
    "def create_dataset(img, map, scaler):\n",
    "    img = scaler(tf.cast(img, tf.float32))\n",
    "    \n",
    "    return img,map\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices(\n",
    "    create_dataset(train_images, train_maps,scaler_neg1_1)\n",
    ")\n",
    "val_data = tf.data.Dataset.from_tensor_slices(\n",
    "    create_dataset(val_images, val_maps,scaler_neg1_1)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pic , seg in train_data.take(1):\n",
    "    print(pic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch = (\n",
    "    train_data.cache()\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .repeat()\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for im , se in train_batch.take(1):\n",
    "    print(im.shape, se.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
